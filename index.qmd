---
title: "Predicting the Unpredictable: Australian Rainfall Dynamics"
author: "Chris Olande"
date: "2026-01-16"
format:
  html:
    toc: true
    toc-location: left  
    toc-depth: 2
    code-fold: true 
    code-tools: true  
    theme: cosmo
    df-print: paged
    fig-width: 10
    fig-height: 6
    embed-resources: true      
execute: 
  echo: true  
  warning: false
  message: false
  cache: false
---

## Introduction

Rainfall in Australia is a story of extremes. Driven by the complex interplay of the Southern Ocean’s Westerlies and the tropical monsoon, Australian weather patterns oscillate violently between prolonged droughts and torrential flood events. For meteorologists and data scientists, modeling this phenomenon presents a dual challenge: predicting **if** it will rain (occurrence) and **how much** will fall (intensity).

This report presents a comprehensive analysis of daily observations from diverse locations across Australia, aiming to accurately model these dynamics using advanced statistical frameworks in **R**.

### The Statistical Challenge

Standard statistical approaches often assume data follows a normal (Gaussian) distribution. However, daily rainfall data violates every assumption of linear regression:

1.  **Zero-Inflation:** Approximately **64%** of observations are dry days (0mm). A standard model struggles to predict exact zeros, often outputting physically impossible negative values.
2.  **Extreme Skewness:** When it does rain, the distribution is highly right-skewed. The "long tail" of storm events drives the bulk of the variance.
3.  **Spatiotemporal Dependence:** Rain is not independent. A wet day in Darwin does not behave like a wet day in Melbourne, and a wet yesterday strongly predicts a wet today.

To address these challenges, we utilize a **Hurdle Gamma Generalized Linear Mixed Model (GLMM)** framework. This approach explicitly separates the data-generating process into two distinct components:

- **Occurrence (Hurdle)**: A logistic regression models whether rain occurs at all (zero vs. non-zero), treating dry days as a structural state rather than a random outcome from the intensity distribution.
- **Intensity (Gamma)**: Conditional on rain occurring, a Gamma distribution with truncation at zero models the amount of rainfall. This ensures the intensity component never generates zeros or negative values, maintaining physical validity.

Unlike zero-inflated models where the Gamma component can also produce zeros, the hurdle specification strictly enforces that zeros arise only from the binomial hurdle process, while all positive values come from the truncated Gamma. This aligns with the physical rainfall process and improves interpretability of coefficients.

### Objectives

To achieve a robust analysis, this report addresses the following key objectives:

-   **Data Integrity:** Implement a Random Forest imputation strategy to handle missing values without discarding critical information.

-   **Temporal Dynamics:** Investigate the "persistence" effect using Markov Chain analysis to determine how prior weather states influence current rainfall probabilities.

-   **Physical Modeling:** Reconstruct the drivers of rainfall by layering **Moisture**, **Energy**, **Wind Vectors**, and **Spatial Heterogeneity** into the model.

-   **Model Selection:** Rigorously compare standard linear models against the Hurdle Gamma framework using AIC, BIC, and DHARMa residual diagnostics. 

# Computational Environment and Data Ingestion

We begin by loading the necessary R libraries and reading the dataset.

```{r}
#| label: setup-libraries-data
#| echo: true
#| message: false
#| warning: false
#| results: 'hide'

# Initialize environment and load dependencies
librarian::shelf(
  tidyverse,
  tidymodels,
  kableExtra,
  patchwork,
  skimr,
  gridExtra,
  gtsummary,
  janitor,
  corrplot,
  sjPlot,
  scales,
  GGally,
  car,
  forcats,
  performance,
  glmmTMB,
  splines,
  mgcv,
  DHARMa,
  zoo,
  ggpubr,
  ggridges,
  caret,
  rstatix,
  Metrics,
  mice,
  missRanger,
  ranger,
  cocor,
  splines,
  multcompView,
  lmtest,
  aod,
  pROC
)

# Load the dataset
df <- read_csv("data/weatherAUS.csv")
```

This section establishes the computational framework necessary for the analysis. We utilize the `librarian::shelf` function for robust dependency management, ensuring that all required packages are installed and loaded efficiently.

The analytical toolkit assembled here is comprehensive:

-   **Data Wrangling & Cleaning:** The `tidyverse` suite and `janitor` are employed for efficient data manipulation and cleaning.
-   **Advanced Statistical Modeling:** `glmmTMB` and `mgcv` are included to handle complex regression tasks, specifically hurdle models and Generalized Additive Models (GAMs), while `DHARMa` and `performance` are reserved for rigorous model diagnostics and residual analysis.
-   **Imputation & Machine Learning:** `missRanger` and `ranger` provide the framework for the Random Forest-based imputation strategy mentioned in the objectives.
-   **Visualization:** A combination of `patchwork`, `ggpubr`, and `ggridges` is loaded to generate publication-quality, multi-panel figures.

Finally, the primary dataset is ingested into the environment as `df` for immediate processing.

# Analytical Utilities and Helper Functions

```{r}
#| label: global-setup
#| include: false

# Load everything at once
load("models/all_models_bundle.RData")
```

```{r}
#| label: util-functions
#| echo: true
#| message: false
#| warning: false

# quantify and tabulate missing values
missing_val <- function(df) {
  missing_tab <- df %>%
    summarise(across(everything(), ~ mean(is.na(.)) * 100)) %>%
    pivot_longer(
      everything(),
      names_to = "column",
      values_to = "pct_missing"
    ) %>%
    arrange(desc(pct_missing))

  return(
    missing_tab %>% kable(caption = "Percentage of Missing Values by Feature")
  )
}

# multicollinearity via Variance Inflation Factor (VIF)
mc_check <- function(data) {
  vif_check <- lm(rainfall ~ ., data = data)
  test_collinearity <- check_collinearity(vif_check)
  return(test_collinearity)
}

# execute feature selection and dimensionality reduction
select_model_features <- function(data, keep_location = TRUE) {
  # Define list of redundant or highly correlated features to exclude
  cols_to_drop = c(
    "month",
    "day",
    "day_of_year",
    "date",
    "temp9am",
    "temp3pm",
    "min_temp",
    "max_temp",
    "pressure3pm",
    "pressure9am",
    "cloud3pm",
    "cloud9am",
    "dewpoint_3pm",
    "wind_dir3pm",
    "wind_speed3pm",
    "wind_gust_dir",
    "wind_gust_speed",
    "wind_speed9am",
    "wind_dir9am",
    "wind9am_rad",
    "gust_rad",
    "moisture_index",
    "rain_today"
  )

  # Conditionally drop location if analyzing aggregate data
  if (!keep_location) {
    cols_to_drop <- c(cols_to_drop, "location")
  }

  # Remove imputation flags if present
  imp_flags <- names(data)[grepl("_imp_flagged$", names(data))]
  cols_to_drop <- c(cols_to_drop, imp_flags)

  data <- data %>%
    select(-any_of(cols_to_drop)) %>%
    ungroup()

  return(data)
}

# standardize numeric predictors (Z-score scaling)
scale_data <- function(data) {
  df_scaled <- data %>%
    mutate(across(
      .cols = where(is.numeric) & !c("rainfall"),
      .fns = scale
    ))

  return(df_scaled)
}
```

To ensure reproducibility and streamline the data processing pipeline, we established a suite of utility functions designed to address specific statistical requirements:

-   **Missingness Assessment (`missing_val`):** A diagnostic tool that aggregates and computes the percentage of missing data per variable. This is critical for identifying features that may require aggressive imputation or exclusion.
-   **Multicollinearity Diagnostics (`mc_check`):** To safeguard the stability of our regression coefficients, this function employs the Variance Inflation Factor (VIF). It identifies highly correlated predictors that could artificially inflate standard errors and obscure the true relationship between weather variables and rainfall.
-   **Feature Selection (`select_model_features`):** This function enforces parsimony by removing redundant variables (e.g., intermediate temperature readings like `temp9am` and `temp3pm`) and non-informative administrative columns. This reduction in dimensionality is essential to prevent overfitting and improve model convergence.
-   **Standardization (`scale_data`):** Finally, we implement Z-score scaling for all numeric predictors (excluding the target variable `rainfall`). This ensures that features with different units (e.g., pressure in hPa vs. wind speed in km/h) contribute equally to the model optimization process.

# Data Cleaning and Preprocessing

```{r}
#| label: data-cleaning
#| echo: true
#| message: false
#| warning: false

df_clean <- df %>%
  clean_names() %>%
  mutate(
    date = as.Date(date),
    month = as.factor(month(date)),
    day = as.factor(wday(date, label = TRUE))
  ) %>%
  # Remove records where the target variable (rainfall) is missing
  filter(!is.na(rainfall))


df_clean %>%
  head() %>%
  kable(caption = "Head of Cleaned Dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

df_clean %>%
  tail() %>%
  kable(caption = "Tail of Cleaned Dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

In this phase, we transform the raw dataset `df` into a consistent format suitable for analysis (`df_clean`). The preprocessing pipeline involves three primary operations:

1.  **Syntactic Standardization:** The `clean_names()` function is applied to convert all column headers to `snake_case`, ensuring consistent variable naming conventions across the dataset.
2.  **Temporal Feature Extraction:** The `date` column is cast to a proper Date object. From this, we derive two key categorical variables: `month` (to capture seasonal rainfall variations) and `day` (representing the day of the week). These derived features will be essential for identifying temporal patterns in precipitation.
3.  **Target Integrity:** We explicitly exclude observations where the target variable, `rainfall`, is missing (`NA`). Since our primary objective is to model rainfall occurrence and intensity, records without this ground truth provide no supervised learning value and are therefore removed.

The resulting tables (Head and Tail) confirm the successful standardization of variables and the existence of the newly engineered temporal features.

# Exploratory Data Analysis

## Temporal Dynamics of Rainfall Occurrence

```{r}
#| label: temporal-dist
#| echo: true
#| message: false
#| warning: false

# Day Distribution Table
df_clean %>%
  filter(rainfall > 0) %>%
  tabyl(day) %>%
  adorn_pct_formatting() %>%
  arrange(desc(n)) %>%
  kable(
    caption = "Frequency of Rainfall Days by Day of the Week",
    col.names = c("Day", "Count (n)", "Percentage")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Month Distribution Table
df_clean %>%
  filter(rainfall > 0) %>%
  tabyl(month) %>%
  adorn_pct_formatting() %>%
  arrange(desc(n)) %>%
  kable(
    caption = "Frequency of Rainfall Days by Month",
    col.names = c("Month", "Count (n)", "Percentage")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Cross-tabulation: Month vs Day
df_clean %>%
  filter(rainfall > 0) %>%
  tabyl(month, day) %>%
  adorn_totals(c("row", "col")) %>%
  kable(caption = "Cross-tabulation of Rainfall Frequency: Month vs. Day") %>%
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 11
  ) %>%
  scroll_box(width = "100%")
```

To understand the temporal drivers of precipitation, we analyzed the frequency of wet days (rainfall \> 0) across weekly and monthly cycles.

**Weekly Variation:** The distribution of rainfall across the days of the week appears largely uniform, with a slight variation in frequency. Tuesdays (14.7%) and Mondays (14.6%) exhibit the highest incidence of rain, while weekends (Saturday and Sunday) show marginally lower frequencies (approx. 13.8%). Statistically, this suggests that the mechanism generating rainfall is independent of the anthropogenic weekly cycle, as expected in meteorological data.

**Seasonal (Monthly) Variation:** In contrast, the monthly distribution reveals distinct seasonal patterns.

-   **Peak Season:** The winter months of June (10.7%) and July (10.3%) record the highest frequency of rainfall events, consistent with the southern hemisphere's winter weather patterns which often bring frontal systems to southern Australia.
-   **Low Season:** The summer months, particularly February (6.5%) and December (7.0%), exhibit the lowest frequency of rain days.

**Interaction Effects:** The cross-tabulation of Month versus Day confirms that the seasonal signal dominates the weekly noise. For instance, the high counts in June and July are robustly distributed across all days of the week (e.g., June averages \~750-800 events per day), whereas February counts drop significantly (averaging \~450-480 events per day). This validates the necessity of including `Month` as a seasonal predictor in our subsequent modeling, while `Day` may serve as a minor control variable.

## Assessment of Data Completeness

```{r}
#| label: missing-values
#| echo: true
#| message: false
#| warning: false

# Calculate total count of missing values in the entire dataframe
total_na <- sum(is.na(df_clean))
print(paste("Total Missing values:", total_na))

# Generate missingness table using the utility function defined earlier
missing_val(df_clean)
```

A critical examination of missing data reveals significant gaps in specific meteorological measurements. While the total number of missing entries is substantial (314,146), the missingness is not uniformly distributed across features:

-   **High Missingness:** The variables `sunshine` (47.7%) and `evaporation` (42.5%) exhibit the highest rates of missing data. This is likely due to the limited availability of specialized recording equipment at smaller weather stations.
-   **Moderate Missingness:** Cloud cover observations (`cloud3pm` and `cloud9am`) are missing in approximately 37–40% of records, suggesting potential observational challenges or station-specific reporting protocols.
-   **Low Missingness:** Critical core variables, including `pressure`, `wind`, and `temperature`, show much lower missingness rates (\< 10%).

**Implications for Modeling:** The severity of missingness in `sunshine` and `evaporation` poses a strategic dilemma. Applying standard listwise deletion (removing any row with a missing value) would result in the loss of nearly half the dataset, potentially introducing bias and reducing statistical power. This finding empirically justifies the **Random Forest imputation strategy** proposed in the study's objectives. By imputing these values rather than discarding them, we preserve the integrity of the dataset and allow for the inclusion of these potentially predictive features in the final models.

## Distributional Characteristics of the Target Variable

```{r}
#| label: target-stats
#| echo: true
#| message: false
#| warning: false

rainfall_stats <- df_clean %>%
  summarise(
    n = n(),
    mean = mean(rainfall),
    median = median(rainfall),
    sd = sd(rainfall),
    min = min(rainfall),
    max = max(rainfall),
    q25 = quantile(rainfall, 0.25),
    q75 = quantile(rainfall, .75),
    iqr = IQR(rainfall),
    n_zeros = sum(rainfall == 0),
    pct_zeros = mean(rainfall == 0) * 100,
    n_large = sum(rainfall > 100),
    pct_large = mean(rainfall > 100) * 100,
    skewness = moments::skewness(rainfall),
    kurtosis = moments::kurtosis(rainfall)
  )

# Transpose and format
rainfall_stats %>%
  pivot_longer(everything(), names_to = "Statistic", values_to = "Value") %>%
  mutate(
    Value = ifelse(
      Value > 1000,
      format(Value, scientific = TRUE, digits = 3),
      round(Value, 3)
    )
  ) %>%
  kable(
    caption = "Descriptive Statistics: Daily Rainfall (mm)",
    align = "lr"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Structural Zeros Check (Dry vs. Wet Days)
# Note: "Zero-inflation" here refers to the data characteristic (prevalence of zeros),
# not the modeling approach. We use a hurdle model to handle this data structure.
rain_check <- df_clean %>%
  summarise(
    total_days = n(),
    dry_days = sum(rainfall == 0),
    rainy_days = sum(rainfall > 0),
    zero_inflation_pct = (dry_days / total_days) * 100
  )


rain_check %>%
  kable(
    caption = "Prevalence of Zero-Inflation (Dry Days)",
    col.names = c(
      "Total Days",
      "Dry Days (0mm)",
      "Rainy Days (>0mm)",
      "Zero Inflation (%)"
    )
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "bordered"),
    full_width = FALSE
  )
```

A deep statistical examination of the target variable, `rainfall`, confirms extreme distributional irregularities that challenge standard modeling approaches.

**Central Tendency and Dispersion:** The data exhibits a massive discrepancy between the mean (2.36 mm) and the median (0.00 mm). This zero-median property immediately signals a highly skewed distribution. The standard deviation (8.48 mm) is nearly four times the mean, indicating high variability and volatility in daily precipitation.

**Zero-Inflation:** The most critical finding is the prevalence of zero-inflation. Out of 142,199 recorded observations, 91,080 are dry days. This translates to a **zero-inflation rate of 64.05%**. In statistical terms, this "hurdle" of zeros implies that any predictive model must effectively answer two distinct questions: "Will it rain?" (binary classification) and "If so, how much?" (regression).

**Tail Behavior:** The distribution is extremely heavy-tailed.

-   **Skewness (9.84):** Indicates a severe rightward skew, with the mass of the data concentrated near zero and a long tail extending towards extreme values.

-   **Kurtosis (181.15):** This exceptionally high value points to a "leptokurtic" distribution, meaning extreme outliers are far more frequent than in a normal distribution. The maximum recorded rainfall of 371 mm, alongside 151 events exceeding 100 mm, confirms the presence of extreme weather events that models must be robust enough to handle.

**Conclusion:** The combination of \~64% zeros and extreme kurtosis confirms that a standard Gaussian Linear Model (OLS) would be severely biased. These statistics strongly support the adoption of a **Hurdle Gamma** framework to separately model the zero-state (occurrence) and the positive continuous state (intensity). Unlike zero-inflated models, the hurdle specification ensures that the Gamma component is strictly truncated at zero, preventing it from generating zeros and maintaining clear separation between the occurrence and intensity processes.

## Bivariate Correlation Analysis

```{r}
#| label: correlation-table
#| echo: true
#| message: false
#| warning: false

# Select numeric columns excluding the target
numeric_cols <- df_clean %>%
  select(where(is.numeric)) %>%
  names()
numeric_cols <- numeric_cols[numeric_cols != "rainfall"]

# Compute Spearman correlations and format interpretation
cors <- df_clean %>%
  rstatix::cor_test(
    vars = "rainfall",
    vars2 = numeric_cols,
    method = "spearman"
  ) %>%
  filter(!is.na(cor)) %>%
  arrange(desc(abs(cor))) %>%
  dplyr::select(var2, cor, p) %>%
  mutate(
    interpretation = case_when(
      abs(cor) < 0.1 ~ "Negligible",
      abs(cor) < 0.3 ~ "Small",
      abs(cor) < 0.5 ~ "Moderate",
      TRUE ~ "Large"
    )
  )


cors %>%
  kable(
    caption = "Spearman Correlation with Rainfall (Ranked by Strength)",
    col.names = c("Predictor", "Correlation (r)", "P-Value", "Strength")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r}
#| label: fig-correlation-matrix
#| fig-cap: "Spearman Correlation Matrix of Meteorological Features. Red indicates negative correlation; Blue indicates positive correlation."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

# Calculate full pairwise correlation matrix
cor_matrix <- df_clean %>%
  select(where(is.numeric)) %>%
  cor(use = "pairwise.complete.obs", method = "spearman")

# Reshape for ggplot
cor_melt <- cor_matrix %>%
  as.data.frame() %>%
  rownames_to_column(var = "Var1") %>%
  pivot_longer(cols = -Var1, names_to = "Var2", values_to = "Correlation")

# Generate Heatmap
cor_melt %>%
  ggplot(aes(x = Var1, y = Var2, fill = Correlation)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "#D73027",
    mid = "white",
    high = "#4575B4",
    midpoint = 0,
    limit = c(-1, 1),
    name = "Spearman\nCorrelation"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, size = 10, hjust = 1),
    axis.text.y = element_text(size = 10),
    axis.title = element_blank(),
    panel.grid.major = element_blank(),
    legend.position = "right"
  ) +
  # Add correlation coefficients for significant relationships
  geom_text(
    data = filter(cor_melt, abs(Correlation) > 0.3),
    aes(label = round(Correlation, 2)),
    color = "black",
    size = 3
  ) +
  labs(
    title = "Feature Correlation Matrix",
    subtitle = "Strongest predictors: Humidity (Positive) and Sunshine (Negative)"
  )
```

```{r}
#| label: correlation-significance-test
#| echo: true
#| collapse: true

# Hypothesis: Is Humidity (3pm) a significantly different predictor than Sunshine?
cor_humidity <- cor.test(
  df_clean$rainfall,
  df_clean$humidity3pm,
  method = "spearman"
)
cor_sunshine <- cor.test(
  df_clean$rainfall,
  df_clean$sunshine,
  method = "spearman"
)

# Compare the two dependent correlations using Steiger's Z-test
# Tests if the difference between r_humidity and r_sunshine is non-zero
cocor_result <- cocor.dep.groups.overlap(
  r.jk = cor_humidity$estimate, # Rainfall vs Humidity
  r.jh = cor_sunshine$estimate, # Rainfall vs Sunshine
  r.kh = cor(
    df_clean$humidity3pm,
    df_clean$sunshine,
    use = "complete.obs",
    method = "spearman"
  ), # Humidity vs Sunshine
  n = nrow(df_clean),
  alternative = "two.sided",
  test = "steiger1980", # Using Steiger's Z for robustness
  return.htest = TRUE
)

print(cocor_result)
```

To identify the primary meteorological drivers of rainfall, we performed a Spearman rank correlation analysis. This non-parametric method was selected to accommodate the non-linear, skewed nature of the rainfall data identified in the previous section.

**Key Predictors:** As visualized in @fig-correlation-matrix, the analysis reveals two distinct clusters of predictive features:

1.  **Positive Drivers:** `Humidity3pm` ($r = 0.44$) and `Cloud Cover` ($r \approx 0.37$) show the strongest positive association with rainfall. This aligns with physical expectations: higher atmospheric moisture and cloud density are precursors to precipitation.
2.  **Negative Drivers:** `Sunshine` ($r = -0.40$) and `Evaporation` ($r = -0.31$) exhibit the strongest negative correlations. Increased solar exposure and evaporation rates typically indicate clear skies and high pressure systems, conditions unfavorable for rain.

**Multicollinearity Warning:** The heatmap also highlights significant collinearity among predictors. For instance, `temp9am` and `temp3pm` are highly correlated ($r > 0.8$), as are `pressure9am` and `pressure3pm` ($r = 0.96$). This reinforces the necessity of the VIF-based feature selection strategy outlined in our methodology to prevent model instability.

**Statistical Validation:** To confirm that the opposing effects of moisture and solar radiation are statistically distinct, we applied Steiger’s Z-test for dependent correlations ($z \approx 188.9, p < 2.2e-16$). While this formally rejects the null hypothesis, we exercise caution in interpreting the p-value; in datasets of this magnitude ($N > 140,000$), statistical significance is often achieved even for trivial effects due to high power. However, the substantial magnitude of the Z-statistic confirms that the difference is not merely an artifact of sample size. We therefore conclude that `Humidity3pm` and `Sunshine` represent distinct, opposing physical forces in the generation of Australian rainfall, rather than relying solely on the p-value for "certainty."

# Hybrid Imputation Strategy

```{r}
#| label: imputation-strategy
#| echo: true
#| eval: false

clean_and_impute_weather <- function(df) {
  # Mode function for categorical data
  calc_mode <- function(x) {
    ux <- unique(na.omit(x))
    if (length(ux) == 0) {
      return(NA)
    }
    ux[which.max(tabulate(match(x, ux)))]
  }

  # Basic cleaning and temporal feature engineering
  df <- df %>%
    clean_names() %>%
    mutate(
      date = as.Date(date),
      month = as.factor(month(date)),
      day = as.factor(wday(date, label = TRUE))
    ) %>%
    filter(!is.na(rainfall)) %>%
    select(-rain_tomorrow) # Remove future leakage variables

  # Flag "Informative Missingness"
  flagged_df <- df %>%
    mutate(
      sunshine_imp_flagged = ifelse(is.na(sunshine), 1, 0),
      evap_imp_flagged = ifelse(is.na(evaporation), 1, 0),
      cloud3pm_imp_flagged = ifelse(is.na(cloud3pm), 1, 0),
      cloud9am_imp_flagged = ifelse(is.na(cloud9am), 1, 0)
    )

  # Temporal Interpolation (LOCF/Linear)
  # Weather is autocorrelated; interpolate short gaps within specific locations first
  interp_vars <- c(
    "min_temp",
    "max_temp",
    "temp9am",
    "temp3pm",
    "pressure9am",
    "pressure3pm",
    "humidity9am",
    "humidity3pm"
  )

  flagged_df <- flagged_df %>%
    group_by(location) %>%
    mutate(across(
      all_of(interp_vars),
      ~ na.approx(., maxgap = 5, na.rm = FALSE, rule = 2)
    )) %>%
    ungroup()

  # Random Forest Imputation (missRanger)
  # Use Predictive Mean Matching (PMM) to handle remaining complex missing patterns
  metadata_cols <- flagged_df %>% select(date)
  imputation_cols <- flagged_df %>% select(-date)

  imputed_data <- missRanger(
    imputation_cols,
    pmm.k = 5, # Predictive Mean Matching k-neighbors
    num.trees = 100, # Robustness
    sample.fraction = 0.3,
    min.node.size = 10,
    seed = 123,
    verbose = 1,
    maxiter = 5
  )

  imputed_df <- bind_cols(metadata_cols, imputed_data)
  return(imputed_df)
}
```

```{r}
#| label: clean-and-save-imputed
#| message: false
#| warning: false
#| eval: false

df_final <- clean_and_impute_weather(df)
write_csv(df_final, "data/df_final.csv")
```

```{r}
#| label: load-imputed-data
#| echo: false
#| message: false
#| warning: false

# Load the pre-computed dataset to save rendering time
df_final <- read_csv("data/df_final.csv")
```

To address the missing data challenges identified in the EDA (specifically the high missingness in `sunshine` and `evaporation`), we implemented a robust, multi-stage hybrid imputation strategy designed to preserve the statistical properties of meteorological data.

**1. Informative Missingness Flags:** Before imputation, we generated binary flags (e.g., `sunshine_imp_flagged`) for variables with high missingness. This ensures that if the absence of data itself carries information (e.g., a broken sensor during a specific storm type), the model retains the capacity to learn from it.

**2. Temporal Interpolation (Time-Series Logic):** Recognizing that weather variables like temperature and pressure exhibit strong temporal autocorrelation, we first applied linear interpolation (`na.approx`) grouped by `Location`.

-   **Rationale:** If the temperature is $20^\circ$C on Monday and $22^\circ$C on Wednesday, it is physically sound to estimate Tuesday as $21^\circ$C rather than using a global average.
-   **Constraint:** This was limited to a `maxgap` of 5 days to prevent creating artificial data over long periods of sensor failure.

**3. Multivariate Imputation via Chained Random Forests:** For remaining gaps, particularly those in non-continuous variables like `cloud cover` or `wind direction`, we utilized the `missRanger` algorithm.

-   **Method:** This technique uses Random Forests to predict missing values based on all other available variables iteratively.
-   **Advantage:** Unlike mean imputation, which shrinks variance, `missRanger` with Predictive Mean Matching (PMM) preserves the original distribution and the complex non-linear correlations between weather features.

This comprehensive approach ensures `df_final` is complete, statistically sound, and ready for advanced modeling.

# Pattern Analysis

## Temporal Dependence and Markov Chain Analysis

```{r}
#| label: markov-prep
#| echo: true
#| message: false
#| warning: false

# Construct Markov transitions by lagging the 'rain_today' variable
# Grouping by location ensures we don't lag across different cities
markov_table <- df_final %>%
  group_by(location) %>%
  arrange(date) %>%
  mutate(yesterday_rain = lag(rain_today)) %>%
  ungroup() %>%
  filter(!is.na(rain_today), !is.na(yesterday_rain)) %>%
  count(yesterday_rain, rain_today)

# Create contingency table for statistical testing
cont_table <- markov_table %>%
  pivot_wider(names_from = rain_today, values_from = n, values_fill = 0) %>%
  column_to_rownames("yesterday_rain") %>%
  as.matrix()

# Display raw counts
print(cont_table)
```

```{r}
#| label: markov-stats
#| echo: true
#| collapse: true

# Pearson's Chi-squared Test for Independence
# H0: Rain today is independent of rain yesterday
chi_result <- chisq_test(as.table(cont_table))
print(chi_result)

# Effect Size Calculation (Cramér's V)
cramers_v <- cramer_v(cont_table)


cat("\nEffect Size Interpretation\n")
cat(sprintf("V = %.4f: ", cramers_v))
if (cramers_v < 0.1) {
  cat("Negligible Association\n")
} else if (cramers_v < 0.3) {
  cat("Weak Association\n")
} else if (cramers_v < 0.5) {
  cat("Moderate Association\n")
} else {
  cat("Strong Association\n")
}
```

```{r}
#| label: fig-markov-chain
#| fig-cap: "Markov Chain Transition Matrix: Visualizing the 'Persistence Effect' in Australian Rainfall."
#| fig-width: 8
#| fig-height: 7
#| echo: true
#| warning: false

# Calculate transition probabilities for plotting
markov_data <- df_final %>%
  group_by(location) %>%
  arrange(date) %>%
  mutate(yesterday_rain = lag(rain_today)) %>%
  ungroup() %>%
  filter(!is.na(rain_today), !is.na(yesterday_rain))

markov_data %>%
  count(yesterday_rain, rain_today) %>%
  group_by(yesterday_rain) %>%
  mutate(prob = n / sum(n)) %>%
  ggplot(aes(x = yesterday_rain, y = rain_today, fill = prob)) +
  geom_tile() +
  geom_text(
    aes(label = scales::percent(prob, accuracy = 1)),
    color = "white",
    size = 8,
    fontface = "bold"
  ) +
  scale_fill_viridis_c(option = "viridis", begin = 0.2, end = 0.8) +
  labs(
    title = "Markov Chain: Rain Persistence Effect",
    subtitle = sprintf(
      "X^2 = %.2f, p < 0.001, Cramer's V = %.3f (Moderate Association)\nYesterday's rain strongly predicts today's rain state.",
      chi_result$statistic,
      cramers_v
    ),
    x = "Did it Rain Yesterday?",
    y = "Did it Rain Today?",
    fill = "Probability"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14, face = "bold"),
    plot.title = element_text(size = 16, face = "bold")
  )
```

To quantify the "persistence" of weather patterns (the tendency of current weather to resemble past weather), we modeled the rainfall sequence as a first-order Markov Chain. This approach tests the hypothesis that the probability of rain today ($P(\text{Rain}_t)$) is conditionally dependent on the state of the previous day ($P(\text{Rain}_{t-1})$).

**Statistical Significance:** The Pearson Chi-squared test ($\chi^2 \approx 13,718, p < 0.001$) overwhelmingly rejects the null hypothesis of independence. Furthermore, Cramér's V ($V \approx 0.31$) indicates a **moderate effect size**, confirming that yesterday’s weather is not just statistically significant but practically meaningful for prediction.

**Transition Probabilities:** As illustrated in @fig-markov-chain, the transition matrix reveals distinct stability patterns:

-   **Dry Persistence (Stability):** If it was dry yesterday, there is an **85% probability** it will remain dry today. This highlights the stability of high-pressure systems in the Australian climate.
-   **Wet Persistence (Instability):** If it rained yesterday, there is only a **47% probability** it will rain again today. Conversely, there is a 53% chance the weather will clear up.

**Conclusion:** While the "Dry" state is highly stable (sticky), the "Wet" state is transient. This asymmetry suggests that while past rainfall is a useful predictor, it cannot be the *sole* predictor. A robust model must incorporate other meteorological covariates (humidity, pressure) to accurately predict the onset and cessation of rainfall events.

## Justification for Interaction Terms

```{r}
#| label: fig-interaction-rain-corner
#| fig-cap: "Bivariate Density Plot of Humidity vs. Sunshine, faceted by Rainfall Occurrence. The concentration of the 'Yes' class in the upper-left quadrant (High Humidity, Low Sunshine) visually justifies the inclusion of an interaction term."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

df_final %>%
  group_by(location) %>%
  arrange(date) %>%
  mutate(
    # Create a reference index for the last rainy day
    rain_index_ref = ifelse(rainfall > 0, row_number(), NA_integer_)
  ) %>%
  fill(rain_index_ref, .direction = "down") %>%
  mutate(
    # Calculate days elapsed since the last rainfall event
    days_since_rain = row_number() - lag(rain_index_ref)
  ) %>%
  select(-rain_index_ref) %>%
  # Plotting the "Rain Corner"
  ggplot(aes(sunshine, humidity3pm)) +
  geom_density2d_filled(continuous_var = "ndensity", bins = 7) +
  facet_wrap(~rain_today, labeller = label_both) +
  scale_fill_brewer(palette = "Blues") +
  labs(
    title = "Justifying Interaction: The 'Rain Corner'",
    subtitle = "Rain (Right) concentrates in High Humidity/Low Sun, while No Rain (Left) is spread out.\nThis structural difference justifies a 'Sunshine * Humidity' interaction feature.",
    x = "Sunshine (hours)",
    y = "Humidity 3pm (%)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 14, face = "bold")
  )
```

To refine our model specification, we investigated potential non-linear interactions between key predictors. Specifically, we examined the joint distribution of `Humidity3pm` and `Sunshine`, conditional on the occurrence of rain (`rain_today`).

**The "Rain Corner" Phenomenon:** As demonstrated in @fig-interaction-rain-corner, the two weather states exhibit fundamentally different geometric structures in feature space:

-   **Dry State (`rain_today: No`):** The density is dispersed broadly across the plot. It is possible to have high humidity without rain (if other conditions like pressure prevent it) or high sunshine without rain. The relationship is loose and unstructured.
-   **Wet State (`rain_today: Yes`):** The density collapses into a distinct, tight cluster in the upper-left quadrant, a region we term the **"Rain Corner"**. Rain occurs almost exclusively when **Humidity is High (\>50%) AND Sunshine is Low (\<5 hours)**.

**Modeling Implication:** This stark visual contrast confirms that `Humidity` and `Sunshine` do not act independently. The effect of humidity on rainfall probability is conditional on the level of sunshine. Consequently, a standard additive model ($Rain \sim Humidity + Sunshine$) would fail to capture this specific "corner" effect. This finding empirically justifies the inclusion of a multiplicative interaction term ($Humidity \times Sunshine$) in our final model to mathematically capture this synergistic threshold.

## The 'Drying Effect' and Temporal Decay

```{r}
#| label: dry-spell-prep
#| echo: true
#| message: false
#| warning: false

# Construct 'Days Since Last Rain' counter for each location
dry_spell_data <- df_final %>%
  group_by(location) %>%
  arrange(date) %>%
  mutate(
    did_rain_yesterday = lag(rainfall > 0, default = FALSE),
    # Identify unique dry spells by cumulative sum of wet days
    dry_spell_id = cumsum(did_rain_yesterday)
  ) %>%
  group_by(location, dry_spell_id) %>%
  mutate(days_since_rain = row_number()) %>%
  ungroup() %>%
  # Filter to focus on the first month of a dry spell for stability
  filter(days_since_rain <= 30) %>%
  mutate(rain_binary = as.numeric(rainfall > 0))
```

```{r}
#| label: dry-spell-model
#| echo: true
#| collapse: true

# Fit Logistic Regression (Linear Trend)
# Hypothesis: As the dry spell lengthens, probability of rain decreases
logit_model <- glm(
  rain_binary ~ days_since_rain,
  data = dry_spell_data,
  family = binomial(link = "logit")
)

# Wald Test for Coefficient Significance
# Tests if the 'days_since_rain' effect is significantly different from 0
wald_test <- aod::wald.test(
  b = coef(logit_model),
  Sigma = vcov(logit_model),
  Terms = 2
)

# Calculate Odds Ratios
or_results <- tidy(logit_model, conf.int = TRUE, exponentiate = TRUE) %>%
  filter(term == "days_since_rain")

# Output Results
print(wald_test)
cat(sprintf(
  "\nFor each additional day without rain, odds of rainfall decrease by %.1f%%\n",
  (1 - or_results$estimate) * 100
))
cat(sprintf(
  "95%% CI: [%.3f, %.3f]\n",
  or_results$conf.low,
  or_results$conf.high
))
```

```{r}
#| label: dry-spell-spline
#| echo: true
#| collapse: true

# Fit a Natural Spline model (df=4) to detect non-linear patterns
logit_spline <- glm(
  rain_binary ~ splines::ns(days_since_rain, df = 4),
  data = dry_spell_data,
  family = binomial
)

# Likelihood Ratio Test (LRT): Compare Linear vs. Spline Model
# H0: The relationship is linear (simpler model is sufficient)
lrt_result <- anova(logit_model, logit_spline, test = "LRT")
print(lrt_result)
```

```{r}
#| label: fig-dry-spell
#| fig-cap: "The 'Drying Effect': Empirical vs. Modeled Probability of Rainfall. The probability of rain decays exponentially as the dry spell lengthens."
#| fig-width: 9
#| fig-height: 7
#| echo: true
#| warning: false

# Generate predictions for the trend line
pred_data <- data.frame(days_since_rain = 1:30)
pred_data$pred_prob <- predict(
  logit_model,
  newdata = pred_data,
  type = "response"
)
pred_data$pred_se <- predict(
  logit_model,
  newdata = pred_data,
  type = "response",
  se.fit = TRUE
)$se.fit

# Calculate empirical probabilities (Actual data points)
empirical_probs <- dry_spell_data %>%
  group_by(days_since_rain) %>%
  summarise(
    prob_rain = mean(rain_binary, na.rm = TRUE),
    n = n(),
    se = sqrt(prob_rain * (1 - prob_rain) / n)
  )

# Plot
ggplot() +
  geom_ribbon(
    data = pred_data,
    aes(
      x = days_since_rain,
      ymin = pred_prob - 1.96 * pred_se,
      ymax = pred_prob + 1.96 * pred_se
    ),
    alpha = 0.2,
    fill = "firebrick"
  ) +
  geom_line(
    data = pred_data,
    aes(x = days_since_rain, y = pred_prob),
    color = "firebrick",
    size = 1.2,
    linetype = "dashed"
  ) +
  # Empirical Data (Points + Error Bars)
  geom_pointrange(
    data = empirical_probs,
    aes(
      x = days_since_rain,
      y = prob_rain,
      ymin = prob_rain - 1.96 * se,
      ymax = prob_rain + 1.96 * se
    ),
    size = 0.5,
    color = "black"
  ) +
  scale_y_continuous(
    labels = scales::percent_format(1),
    breaks = pretty_breaks(n = 6)
  ) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  labs(
    x = "Days Since Last Rain",
    y = "Probability of Rainfall",
    title = "Dry Spell Effect on Rain Probability",
    subtitle = sprintf(
      "Logistic Regression: B = %.4f, Wald χ2 = %.2f, p < 0.001\nEach additional dry day reduces odds of rain by %.1f%%",
      coef(logit_model)[2],
      wald_test$result$chi2[1],
      (1 - or_results$estimate) * 100
    ),
    caption = "Points: Empirical probabilities ± 95% CI | Line: Logistic model fit"
  ) +
  theme_minimal()
```

Beyond simple day-to-day persistence, we modeled the **cumulative effect of dry spells** on the probability of rain re-occurring. We formulated this as a survival-style problem: *Does the length of an ongoing drought influence the likelihood of it ending today?*

**Linear Trend Analysis:** A logistic regression model reveals a statistically significant negative relationship (Wald $\chi^2 \approx 8099, p < 0.001$).

-   **The Decay Rate:** The model estimates that for **each additional day** a dry spell continues, the odds of it raining decrease by approximately **16.5%** ($OR = 0.83$).

-   **Physical Interpretation:** This suggests a feedback loop where dry conditions promote stability (e.g., persistent high-pressure ridges), making it progressively harder for rain systems to penetrate as the dry spell lengthens.

**Non-Linear Complexity:** While the linear decay model is robust, the Likelihood Ratio Test comparing it to a Natural Spline model (LRT $\chi^2 \approx 7678, p < 0.001$) indicates significant non-linearity.

-   **Visual Evidence:** As seen in @fig-dry-spell, the empirical data (black dots) shows a "kink" around Day 10-12. The probability of rain drops sharply from Day 1 (\~48%) to Day 10 (\~18%), but then stabilizes or decays much slower from Day 15 to Day 30.
-   **Implication:** A simple linear term underestimates the rapid initial drying and overestimates the decay in long-term droughts. Future models should utilize spline terms for `days_since_rain` to capture this "rapid-then-gradual" decay dynamic.

## Atmospheric Pressure and Diurnal Variation

```{r}
#| label: pressure-prep-normality
#| echo: true
#| message: false
#| warning: false

# Diurnal Pressure Change
pressure_data <- df_final %>%
  mutate(pressure_change = pressure3pm - pressure9am) %>%
  select(rain_today, pressure9am, pressure3pm, pressure_change) %>%
  filter(!is.na(pressure9am), !is.na(rain_today))

# Visual Inspection of Normality (Q-Q Plots)
# Using a random subsample of 5k points for clear visualization
pressure_data %>%
  sample_n(5000) %>%
  pivot_longer(
    cols = c(pressure9am, pressure3pm, pressure_change),
    names_to = "metric",
    values_to = "value"
  ) %>%
  ggplot(aes(sample = value)) +
  stat_qq(alpha = 0.5) +
  stat_qq_line(color = "red") +
  facet_wrap(~metric, scales = "free") +
  labs(
    title = "Q-Q Plots: Checking Normality Assumption",
    subtitle = "Points should hug the red line. Slight deviations are acceptable due to large N (CLT)."
  ) +
  theme_minimal()
```

```{r}
#| label: pressure-stats
#| echo: true
#| message: false

# Prepare data for testing
test_data <- pressure_data %>%
  pivot_longer(
    cols = c(pressure9am, pressure3pm, pressure_change),
    names_to = "metric",
    values_to = "value"
  )

# Execute Welch's t-test (robust to unequal variances)
stats_results <- test_data %>%
  group_by(metric) %>%
  t_test(value ~ rain_today, var.equal = FALSE) %>%
  adjust_pvalue(method = "holm") %>%
  add_significance()

stats_results %>%
  select(metric, group1, group2, statistic, df, p.adj, p.adj.signif) %>%
  kable(
    caption = "Welch's Two Sample t-test Results (Bonferroni-Holm Corrected)",
    digits = 3,
    col.names = c(
      "Metric",
      "Group 1",
      "Group 2",
      "t-statistic",
      "df",
      "Adj. P-Value",
      "Significance"
    )
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r}
#| label: pressure-effect-size
#| echo: true
#| message: false

# Calculate Cohen's d Effect Size
effect_sizes <- test_data %>%
  group_by(metric) %>%
  cohens_d(value ~ rain_today, var.equal = FALSE) %>%
  # Categorize magnitude
  mutate(
    magnitude = case_when(
      abs(effsize) < 0.2 ~ "Negligible",
      abs(effsize) < 0.5 ~ "Small",
      abs(effsize) < 0.8 ~ "Medium",
      TRUE ~ "Large"
    )
  )

effect_sizes %>%
  select(metric, effsize, magnitude) %>%
  kable(
    caption = "Cohen's d Effect Size Analysis",
    digits = 3,
    col.names = c("Metric", "Effect Size (d)", "Interpretation")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r}
#| label: fig-pressure-violin
#| fig-cap: "Violin Plots of Atmospheric Pressure Variables by Rainfall State. Annotations indicate statistical significance and effect size."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

# Merge statistics for annotation
plot_annotations <- stats_results %>%
  left_join(effect_sizes, by = "metric") %>%
  mutate(
    label_text = sprintf(
      "p %s\nCohen's d = %.2f (%s)",
      p.adj.signif,
      effsize,
      magnitude
    ),
    y_pos = case_when(
      metric == "pressure9am" ~ 1045,
      metric == "pressure3pm" ~ 1040,
      metric == "pressure_change" ~ 15
    )
  )

ggplot(test_data, aes(rain_today, value, fill = rain_today)) +
  geom_violin(alpha = 0.6, trim = TRUE) +
  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.8, color = "black") +
  facet_wrap(~metric, scales = "free_y") +
  geom_text(
    data = plot_annotations,
    aes(x = 1.5, y = y_pos, label = label_text),
    inherit.aes = FALSE,
    vjust = 0,
    fontface = "italic",
    size = 3.5
  ) +
  scale_fill_manual(values = c("No" = "#B0B0B0", "Yes" = "#0072B2")) +
  labs(
    title = "Atmospheric Pressure vs. Rainfall",
    subtitle = "Statistical validation using Welch's t-test and Cohen's d effect size",
    y = "Pressure (hPa)",
    x = "Did it rain?"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 12, face = "bold")
  )
```

```{r}
#| label: fig-pressure-means
#| fig-cap: "Comparison of Mean Pressure Levels and Diurnal Drop. Rainy days are characterized by lower absolute pressure and a suppressed diurnal drop."
#| fig-width: 10
#| fig-height: 6
#| echo: true
#| warning: false

data_wide <- df_final %>%
  group_by(rain_today) %>%
  summarise(
    `9:00 AM` = mean(pressure9am, na.rm = TRUE),
    `3:00 PM` = mean(pressure3pm, na.rm = TRUE),
    # Calculate positive drop (9am - 3pm)
    `Pressure Drop` = mean(pressure9am, na.rm = TRUE) -
      mean(pressure3pm, na.rm = TRUE)
  ) %>%
  pivot_longer(cols = -rain_today, names_to = "metric", values_to = "value") %>%
  mutate(
    metric = factor(metric, levels = c("9:00 AM", "3:00 PM", "Pressure Drop")),
    label_txt = round(value, 1)
  )

ggplot(data_wide, aes(x = rain_today, y = value, fill = rain_today)) +
  geom_col(width = 0.6, alpha = 0.9) +
  geom_text(aes(label = label_txt), vjust = -0.5, fontface = "bold", size = 4) +
  facet_wrap(~metric, scales = "free_y", nrow = 1) +
  scale_fill_manual(values = c("No" = "#B0B0B0", "Yes" = "#0072B2")) +
  scale_x_discrete(labels = c("No" = "Dry Days", "Yes" = "Rainy Days")) +
  labs(
    title = "Rainy Days Exhibit Lower Baseline Pressure and Suppressed Diurnal Variation",
    subtitle = "Lower absolute pressure at 9am is the key distinguishing factor",
    y = "Pressure (hPa) / Drop (hPa)",
    x = NULL
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 12),
    plot.subtitle = element_text(color = "grey30", margin = margin(b = 15)),
    axis.text.x = element_text(face = "bold", size = 11),
    strip.text = element_text(face = "bold", size = 12),
    panel.grid.major.x = element_blank()
  )
```

We analyzed atmospheric pressure dynamics to determine how barometric baselines and diurnal fluctuations correlate with rainfall.

**1. Statistical Validity:**

-   **Normality:** The Q-Q plots show that while pressure data generally follows a normal distribution, there are deviations in the tails. However, given our large sample size ($N > 140,000$), the Central Limit Theorem ensures the validity of parametric testing.
-   **Significance:** Welch’s t-test confirms that all pressure metrics are significantly different between dry and rainy days ($p < 0.001$).

**2. Key Findings:**

-   **Baseline Pressure:** Rainy days are characterized by significantly lower atmospheric pressure. As shown in @fig-pressure-means, the mean pressure at 9:00 AM is **1015 hPa for rainy days** compared to **1018.5 hPa for dry days**. This aligns with the meteorological principle that low-pressure systems facilitate cloud formation and precipitation.
-   **Diurnal Drop:** We observed a distinct "suppression" effect on rainy days.
    -   **Dry Days:** Pressure drops significantly by **2.7 hPa** from morning to afternoon, driven by solar heating (thermal lows).
    -   **Rainy Days:** The drop is suppressed to just **1.3 hPa**. Cloud cover likely limits surface heating, reducing the intensity of the thermal low formation.

**3. Effect Size:** The Cohen's $d$ analysis reveals that the **magnitude of change** (`pressure_change`) has a **medium effect size** ($d = -0.72$), which is notably stronger than the absolute pressure readings ($d \approx 0.28-0.48$). This suggests that the *stability* of pressure (or lack thereof) during the day is a potent predictor of rainfall, potentially more so than the raw pressure reading itself.

## Seasonal Dynamics and Intensity Cycles

```{r}
#| label: seasonality-prep
#| echo: true
#| message: false
#| warning: false

# Calculate aggregated monthly statistics (Mean, Median, Count)
monthly_stats <- df_final %>%
  filter(rainfall > 0) %>%
  group_by(month) %>%
  summarise(
    median_rain = median(rainfall),
    mean_rain = mean(rainfall),
    rain_days = n(),
    .groups = "drop"
  ) %>%
  mutate(month_label = factor(month.abb[month], levels = rev(month.abb)))

# Prepare data for density plotting (Log transformation for skewness)
plot_data <- df_final %>%
  filter(rainfall > 0) %>%
  mutate(
    month_label = factor(month.abb[month], levels = rev(month.abb)),
    log_rain = log(rainfall)
  ) %>%
  left_join(monthly_stats, by = c("month", "month_label"))
```

```{r}
#| label: fig-monthly-dist
#| fig-cap: "Ridgeline Plot of Monthly Log-Rainfall Distributions. The shifting peaks illustrate how rainfall intensity varies across the year compared to the global median (dashed line)."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

ggplot(plot_data, aes(log_rain, month_label, fill = after_stat(x))) +
  geom_density_ridges_gradient(
    scale = 2.5,
    rel_min_height = 0.01,
    quantile_lines = TRUE,
    quantiles = 2, # Marks the median
    alpha = 0.8
  ) +
  # Global Median Line for reference
  geom_vline(
    xintercept = median(log(df_final$rainfall[df_final$rainfall > 0])),
    linetype = "dashed",
    color = "grey30",
    linewidth = 0.5
  ) +
  scale_fill_viridis_c(
    option = "mako",
    name = "Log\nRainfall",
    direction = -1
  ) +
  scale_x_continuous(breaks = pretty_breaks()) +
  labs(
    title = "Monthly Rainfall Distribution Patterns",
    subtitle = "Solid lines mark monthly medians vs. the Global Median (dashed).\nNotice how the distribution's shape and center shift cyclically relative to the global baseline.",
    x = "Rainfall Amount (mm, log scale)",
    y = NULL
  ) +
  theme_minimal(base_size = 13)
```

```{r}
#| label: fig-seasonal-facet
#| fig-cap: "Seasonal Rainfall Patterns separated by Meteorological Seasons. Summer months exhibit higher variance and intensity compared to Winter."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

# Assign based on the Australian seasons
seasonal_data <- df_final %>%
  filter(rainfall > 0) %>%
  mutate(
    season = case_when(
      month %in% c(12, 1, 2) ~ "Summer",
      month %in% c(3, 4, 5) ~ "Autumn",
      month %in% c(6, 7, 8) ~ "Winter",
      month %in% c(9, 10, 11) ~ "Spring"
    ),
    season = factor(season, levels = c("Summer", "Autumn", "Winter", "Spring"))
  )
plot_data_seasonal <- seasonal_data %>%
  mutate(month_label = factor(month.abb[month], levels = month.abb))

ggplot(plot_data_seasonal, aes(rainfall, month_label, fill = season)) +
  geom_density_ridges(
    scale = 1.5,
    alpha = 0.7,
    quantile_lines = TRUE,
    quantiles = c(0.25, 0.5, 0.75)
  ) +
  scale_x_log10(
    breaks = c(1, 10, 50, 100, 300),
    labels = label_number(accuracy = 1)
  ) +
  scale_fill_manual(
    values = c(
      "Summer" = "#E69F00",
      "Autumn" = "#D55E00",
      "Winter" = "#0072B2",
      "Spring" = "#009E73"
    )
  ) +
  facet_wrap(~season, scales = "free_y", ncol = 2) +
  labs(
    title = "Seasonal Rainfall Patterns",
    subtitle = "Quartile lines show 25th, 50th, and 75th percentiles",
    x = "Rainfall Amount (mm, log scale)",
    y = NULL
  ) +
  theme_minimal(base_size = 12)

```

```{r}
#| label: fig-mean-rain-bar
#| fig-cap: "Average Rainfall Intensity (Non-Zero Days) by Month. Summer months (Feb/Jan) clearly exhibit higher average rainfall per event than winter months."
#| fig-width: 10
#| fig-height: 6
#| echo: true
#| warning: false

monthly_stats %>%
  mutate(month_label = factor(month.abb[month], levels = month.abb)) %>%
  ggplot(aes(month_label, mean_rain)) +
  geom_col(aes(fill = mean_rain, alpha = 0.8), width = 0.7) +
  geom_text(
    aes(label = round(mean_rain, 1)),
    vjust = -0.5,
    size = 3.5,
    fontface = "bold"
  ) +
  scale_fill_viridis_c(option = "mako", direction = -1) +
  labs(
    title = "Mean Rainfall by Month (Non-Zero Days)",
    subtitle = "Confirms seasonal variation justifying cyclical encoding",
    y = "Mean Rainfall (mm)",
    x = NULL
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(color = "grey30", margin = margin(b = 10)),
    legend.position = "none",
    panel.grid.major.x = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1, face = "bold")
  )
```

While our earlier contingency analysis focused on the *frequency* of rainfall events, this section investigates the *intensity* of rainfall when it does occur.

**1. Cyclical Shifts in Intensity:** The ridgeline analysis reveals a clear cyclical pattern in rainfall distribution relative to the global median.

-   **Summer Peaks:** The distributions for January and February are visibly shifted to the right of the global median (dashed line), indicating that summer storms, while potentially less frequent, are significantly more intense.
-   **Winter Consistency:** In contrast, winter months (June-August) show distributions clustered tightly around lower rainfall values.

**2. Seasonal Variance:** Segmenting the data by season clarifies the mechanism:

-   **Summer (Gold):** Characterized by high variance and "fat tails" extending to \>100mm. The interquartile range (IQR) is wider, reflecting the sporadic nature of convective summer storms.
-   **Winter (Blue):** Characterized by narrower, peaked distributions. The rainfall is consistent but generally lighter, typical of frontal systems.

**3. Mean Intensity Confirmation:** The bar chart quantifies this observation. February records the highest average rainfall per wet day (**10.1 mm**), nearly double that of July (**4.9 mm**). This stark contrast confirms that `Month` carries critical information not just about *whether* it will rain, but *how hard*.

**Modeling Implication:** Because the relationship between Month 12 (Dec) and Month 1 (Jan) is continuous rather than categorical, treating `Month` as a standard factor may lose information. These plots strongly support using **Cyclical Encoding (Sine/Cosine transformation)** for the `Month` variable in our final model to mathematically capture this smooth, wave-like transition from summer peaks to winter troughs.

### Statistical Validation of Seasonal Intensity

```{r}
#| label: seasonal-descriptive-stats
#| echo: true
#| message: false

# Calculate Mean and SD for each season to establish baseline differences
seasonal_stats <- seasonal_data %>%
  select(season, rainfall) %>%
  group_by(season) %>%
  get_summary_stats(rainfall, type = "mean_sd")

seasonal_stats %>%
  kable(
    caption = "Descriptive Statistics of Rainfall Intensity by Season",
    col.names = c("Season", "Variable", "N (Events)", "Mean (mm)", "SD (mm)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r}
#| label: kruskal-wallis-test
#| echo: true
#| message: false

# Kruskal-Wallis Test

kw_result <- kruskal_test(rainfall ~ season, data = seasonal_data)

# Effect Size (Epsilon-squared)
epsilon_sq <- kruskal_effsize(rainfall ~ season, data = seasonal_data)

kw_summary <- tibble(
  Test = "Kruskal-Wallis Rank Sum Test",
  `Chi-squared` = kw_result$statistic,
  df = kw_result$df,
  `P-value` = kw_result$p,
  `Effect Size` = epsilon_sq$effsize,
  Magnitude = as.character(epsilon_sq$magnitude)
)

kw_summary %>%
  mutate(
    `Chi-squared` = round(`Chi-squared`, 2),
    `Effect Size` = round(`Effect Size`, 4),
    `P-value` = scales::pvalue(`P-value`, accuracy = 0.001)
  ) %>%
  kable(
    caption = "Statistical Significance of Seasonal Differences (Non-Parametric)",
    align = "lccccr"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "left"
  ) %>%
  add_footnote(
    c(
      "Effect size measured by Epsilon-squared.",
      "Significance level: alpha = 0.05"
    ),
    notation = "symbol"
  )
```

```{r}
#| label: dunns-test
#| echo: true
#| message: false

# Pairwise comparisons using Dunn's test with Bonferroni correction
dunn_result <- dunn_test(
  rainfall ~ season,
  data = seasonal_data,
  p.adjust.method = "bonferroni"
)

dunn_result %>%
  select(group1, group2, statistic, p.adj, p.adj.signif) %>%
  kable(
    caption = "Dunn's Pairwise Comparison Test (Bonferroni Corrected)",
    col.names = c(
      "Group 1",
      "Group 2",
      "Z-Statistic",
      "Adj. P-Value",
      "Significance"
    )
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r}
#| label: fig-seasonal-stat-groups
#| fig-cap: "Mean Seasonal Rainfall with Statistical Groupings. Letters (a, b, c) indicate significant differences based on Dunn's test (p < 0.05). Seasons sharing the same letter are statistically indistinguishable."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

# Generate Compact Letter Display (CLD)
# Extract p-values and name them by comparison pair
p_vals <- dunn_result$p.adj
names(p_vals) <- paste(dunn_result$group1, dunn_result$group2, sep = "-")

# Generate letters (eg, 'a', 'b', 'ab')
letters_vec <- multcompLetters(p_vals)$Letters

# Create annotation dataframe
letters_df <- data.frame(
  season = names(letters_vec),
  Letter = letters_vec
)

# Aggregation for Plotting
plot_data <- seasonal_data %>%
  group_by(season) %>%
  summarise(
    mean_rain = mean(rainfall, na.rm = TRUE),
    n = n()
  ) %>%
  left_join(letters_df, by = "season")


ggplot(plot_data, aes(x = season, y = mean_rain, fill = season)) +
  geom_col(alpha = 0.8, width = 0.7) +
  # Add Statistical Letters
  geom_text(aes(label = Letter), vjust = -0.5, size = 8, fontface = "bold") +
  # Add Mean Values
  geom_text(
    aes(label = round(mean_rain, 1)),
    vjust = 1.5,
    color = "white",
    fontface = "bold",
    size = 5
  ) +
  scale_fill_manual(
    values = c(
      "Summer" = "#E69F00",
      "Autumn" = "#D55E00",
      "Winter" = "#0072B2",
      "Spring" = "#009E73"
    )
  ) +
  labs(
    title = "Seasonal Rainfall with Statistical Groupings",
    subtitle = sprintf(
      "Kruskal-Wallis: p < 0.001, Effect Size: %s\nSeasons sharing a letter are not significantly different.",
      as.character(epsilon_sq$magnitude)
    ),
    y = "Mean Rainfall (mm)",
    x = NULL
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 16),
    axis.text.x = element_text(size = 12, face = "bold"),
    panel.grid.major.x = element_blank()
  )
```

To robustly confirm the seasonal patterns observed in the exploratory phase, we employed non-parametric statistical testing. The Kruskal-Wallis test was selected over ANOVA due to the skewed, non-normal distribution of rainfall data.

**1. Global Significance:** The Kruskal-Wallis test yields a highly significant result ($\chi^2 = 230, p < 0.001$). This confirms that the differences in rainfall intensity across seasons are not due to random chance. However, the effect size ($\eta^2 \approx 0.004$) is classified as "small," suggesting that while season is a significant predictor, it explains a minor portion of the total variance in rainfall intensity (implying other factors like location and pressure are also critical).

**2. Pairwise Comparisons (Post-Hoc Analysis):** The Dunn’s test with Bonferroni correction reveals three distinct statistical groups, visualized in @fig-seasonal-stat-groups :

-   **Group 'a' (Summer):** Significantly the wettest season ($Mean = 9.1mm$). It stands alone, statistically distinct from all other seasons ($p < 0.001$).
-   **Group 'b' (Autumn & Spring):** These transition seasons are statistically indistinguishable from each other ($p = 1.0$). Their mean intensities ($6.7mm$ and $5.7mm$) represent a middle ground.
-   **Group 'c' (Winter):** Significantly the driest season in terms of intensity ($Mean = 5.5mm$). While visually close to Spring, the statistical test confirms a significant difference ($p_{adj} = 0.026$).

**Modeling Recommendation:** These statistical groupings suggest that we might simplify the model by grouping Autumn and Spring together, or more robustly, using **Cyclical Encoding** (sine/cosine of Month) which naturally handles the smooth transition from the "Peak" (Summer) through the "Transition" (Autumn/Spring) to the "Trough" (Winter).

# Signal Extraction via Moving Averages

```{r}
#| label: ma-feature-engineering
#| echo: true
#| message: false

# Calculate Rolling Moving Averages (3-day and 7-day windows)
# 'align = "right"' ensures no future data leakage (only past/current data used)
ma_data <- df_final %>%
  group_by(location) %>%
  arrange(date) %>%
  mutate(
    rainfall_ma3 = rollmean(rainfall, k = 3, fill = NA, align = "right"),
    rainfall_ma7 = rollmean(rainfall, k = 7, fill = NA, align = "right"),
    humidity_ma3 = rollmean(humidity3pm, k = 3, fill = NA, align = "right"),
    humidity_ma7 = rollmean(humidity3pm, k = 7, fill = NA, align = "right")
  ) %>%
  ungroup()
```

```{r}
#| label: fig-signal-extraction
#| fig-cap: "Signal Extraction: Moving Averages Filter High-Frequency Noise. The 7-Day Moving Average (Green) suppresses daily stochastic variance to reveal the central tendency of wet regimes."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

p1_data <- ma_data %>%
  filter(rainfall > 0) %>%
  select(rainfall, rainfall_ma3, rainfall_ma7) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    metric = factor(
      metric,
      levels = c("rainfall", "rainfall_ma3", "rainfall_ma7"),
      labels = c("Raw Daily", "3-Day MA", "7-Day MA")
    )
  )

ggplot(p1_data, aes(x = value, fill = metric, color = metric)) +
  geom_density(alpha = 0.4, linewidth = 1) +
  annotation_logticks(sides = "b", color = "grey60", linewidth = 0.3) +
  scale_x_log10(
    breaks = c(0.1, 0.5, 1, 5, 10, 50, 100),
    labels = label_number(suffix = " mm"),
    expand = c(0, 0)
  ) +
  scale_fill_manual(
    values = c(
      "Raw Daily" = "#E63946",
      "3-Day MA" = "#F77F00",
      "7-Day MA" = "#06A77D"
    )
  ) +
  scale_color_manual(
    values = c(
      "Raw Daily" = "#E63946",
      "3-Day MA" = "#F77F00",
      "7-Day MA" = "#06A77D"
    )
  ) +
  labs(
    title = "Signal Extraction: Moving Averages Filter High-Frequency Noise",
    subtitle = "Raw rainfall (Red) exhibits high stochastic variance with extreme skew. The 7-Day Moving Average (Green)\nacts as a low-pass filter, suppressing daily noise to reveal the central tendency of wet regimes.",
    x = "Rainfall Intensity (Log Scale)",
    y = "Density",
    caption = "Data: Log-transformed daily rainfall recordings",
    fill = NULL,
    color = NULL
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_line(color = "grey90", size = 0.3),
    panel.grid.major.y = element_line(color = "grey90", size = 0.3),
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(
      color = "grey30",
      size = 11,
      margin = margin(b = 15)
    ),
    axis.text.x = element_text(margin = margin(t = 5))
  )
```

```{r}
#| label: fig-variance-reduction
#| fig-cap: "Variance Reduction by Window Size. Increasing the moving average window size significantly reduces the standard deviation of the signal."
#| fig-width: 8
#| fig-height: 6
#| echo: true
#| warning: false

variance_data <- ma_data %>%
  filter(rainfall > 0) %>%
  summarise(
    Raw = sd(rainfall, na.rm = TRUE),
    `3-Day MA` = sd(rainfall_ma3, na.rm = TRUE),
    `7-Day MA` = sd(rainfall_ma7, na.rm = TRUE)
  ) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "sd") %>%
  mutate(
    metric = factor(metric, levels = c("Raw", "3-Day MA", "7-Day MA")),
    variance_reduction = (sd[1] - sd) / sd[1] * 100
  )

ggplot(variance_data, aes(metric, sd, fill = metric)) +
  geom_col(alpha = 0.8, width = 0.6) +
  geom_text(
    aes(label = sprintf("%.1f mm\n(%.0f%% ↓)", sd, variance_reduction)),
    vjust = -0.3,
    fontface = "bold",
    size = 4.5
  ) +
  scale_fill_manual(
    values = c(
      "Raw" = "#E63946",
      "3-Day MA" = "#F77F00",
      "7-Day MA" = "#06A77D"
    )
  ) +
  labs(
    title = "Variance Reduction by Moving Averages",
    subtitle = "Standard deviation decreases as window increases",
    y = "Standard Deviation (mm)",
    x = NULL
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(color = "grey40", margin = margin(b = 10)),
    legend.position = "none",
    panel.grid.major.x = element_blank(),
    axis.text.x = element_text(face = "bold", size = 12)
  ) +
  ylim(0, max(variance_data$sd) * 1.15)
```

```{r}
#| label: fig-ma-correlation
#| fig-cap: "Feature Correlations: Raw vs Moving Averages. High correlations between MA features (e.g., 0.89 between humidity_ma3 and humidity_ma7) warn of multicollinearity risks."
#| fig-width: 8
#| fig-height: 8
#| echo: true
#| warning: false

cor_data <- ma_data %>%
  select(
    rainfall,
    rainfall_ma3,
    rainfall_ma7,
    humidity3pm,
    humidity_ma3,
    humidity_ma7
  ) %>%
  cor(use = "complete.obs", method = "spearman") %>%
  as.data.frame() %>%
  rownames_to_column("var1") %>%
  pivot_longer(-var1, names_to = "var2", values_to = "correlation") %>%
  mutate(
    var1 = factor(
      var1,
      levels = c(
        "rainfall",
        "rainfall_ma3",
        "rainfall_ma7",
        "humidity3pm",
        "humidity_ma3",
        "humidity_ma7"
      )
    ),
    var2 = factor(
      var2,
      levels = c(
        "rainfall",
        "rainfall_ma3",
        "rainfall_ma7",
        "humidity3pm",
        "humidity_ma3",
        "humidity_ma7"
      )
    )
  )

ggplot(cor_data, aes(var2, var1, fill = correlation)) +
  geom_tile(color = "white", linewidth = 1) +
  geom_text(
    aes(label = sprintf("%.2f", correlation)),
    fontface = "bold",
    size = 3.5
  ) +
  scale_fill_gradient2(
    low = "#0072B2",
    mid = "white",
    high = "#D55E00",
    midpoint = 0,
    limits = c(-1, 1),
    name = "Correlation"
  ) +
  labs(
    title = "Feature Correlations: Raw vs Moving Averages",
    subtitle = "MAs are highly correlated with each other (potential multicollinearity)",
    x = NULL,
    y = NULL
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(color = "grey40", margin = margin(b = 10)),
    axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
    axis.text.y = element_text(face = "bold"),
    panel.grid = element_blank()
  )
```

```{r}
#| label: fig-ma-ridgeline
#| fig-cap: "Distribution Tightening with Moving Averages. Ridgeline plots illustrate how the distribution peaks sharpen and tails compress as the averaging window increases."
#| fig-width: 9
#| fig-height: 7
#| echo: true
#| warning: false

ridge_data <- ma_data %>%
  filter(rainfall > 0) %>%
  select(rainfall, rainfall_ma3, rainfall_ma7) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    metric = factor(
      metric,
      levels = c("rainfall_ma7", "rainfall_ma3", "rainfall"),
      labels = c("7-Day MA", "3-Day MA", "Raw Daily")
    )
  )

ggplot(ridge_data, aes(value, metric, fill = metric)) +
  geom_density_ridges(
    alpha = 0.7,
    scale = 1.5,
    quantile_lines = TRUE,
    quantiles = 2
  ) +
  scale_x_log10(
    breaks = c(1, 5, 10, 25, 50, 100),
    labels = c("1", "5", "10", "25", "50", "100")
  ) +
  scale_fill_manual(
    values = c(
      "Raw Daily" = "#E63946",
      "3-Day MA" = "#F77F00",
      "7-Day MA" = "#06A77D"
    )
  ) +
  labs(
    title = "Distribution Tightening with Moving Averages",
    subtitle = "Peaks become sharper and tails compress as window size increases",
    x = "Rainfall (mm, log scale)",
    y = NULL
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(color = "grey40", margin = margin(b = 15)),
    legend.position = "none",
    axis.text.y = element_text(face = "bold", size = 12),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank()
  )
```

Meteorological data is inherently stochastic; daily rainfall observations are often "noisy" manifestations of underlying weather regimes. To extract the stable climate signal from this high-frequency noise, we applied Moving Average (MA) filters with 3-day and 7-day windows.

**1. Noise Reduction and Variance Suppression:** The effect of this filtering is visually demonstrated in @fig-signal-extraction. The raw daily rainfall (Red curve) exhibits a highly skewed, platykurtic distribution with a long tail of extreme events.

-   **3-Day MA (Orange):** begins to smooth out the extremes.
-   **7-Day MA (Green):** acts as a robust low-pass filter, suppressing the daily variance to reveal a clearer central tendency.

Quantitatively, this smoothing is substantial. As shown in @fig-variance-reduction, the standard deviation of rainfall intensity drops from **13.1 mm (Raw)** to **5.8 mm (7-Day MA)**, a reduction of **56%**. This confirms that the 7-day MA effectively captures the "weekly wetness regime" rather than the unpredictability of a single day.

**2. Correlation and Multicollinearity:** While moving averages improve signal stability, they introduce strong autocorrelation. @fig-ma-correlation reveals:

-   **High Autocorrelation:** The 3-day and 7-day humidity moving averages have a Spearman correlation of **0.89**.
-   **Implication:** Including both raw features and multiple moving averages in a linear model (e.g., Logistic Regression) would likely cause **multicollinearity**, leading to inflated standard errors.

**Conclusion:** Moving averages are powerful for visualizing trends and potentially for tree-based models (Random Forest/XGBoost) that can handle correlated features. However, for linear models, we must select a single temporal window (likely the 3-day MA for responsiveness or 7-day MA for stability) to avoid model instability.

# Strategic Feature Engineering

```{r}
#| label: feature-engineering
#| echo: true
#| message: false
#| warning: false

# Define Compass Lookup Table for Circular Wind Decomposition
compass_lookup <- c(
  "N" = 0,
  "NNE" = 22.5,
  "NE" = 45,
  "ENE" = 67.5,
  "E" = 90,
  "ESE" = 112.5,
  "SE" = 135,
  "SSE" = 157.5,
  "S" = 180,
  "SSW" = 202.5,
  "SW" = 225,
  "WSW" = 247.5,
  "W" = 270,
  "WNW" = 292.5,
  "NW" = 315,
  "NNW" = 337.5
)

df_final <- df_final %>%
  group_by(location) %>%
  arrange(date) %>%
  mutate(
    # Lagging MA by 1 day ensures we predict 'Today' using only 'Yesterday's' trends to prevent data leakage
    rainfall_ma7 = lag(
      rollmean(rainfall, k = 7, fill = NA, align = "right"),
      n = 1
    ),
    humidity_ma7 = lag(
      rollmean(humidity3pm, k = 7, fill = NA, align = "right"),
      1
    ),

    # Dry Spell Calculation
    rain_event_id = cumsum(lag(rainfall, 1) > 0),
    days_since_rain = row_number() - match(rain_event_id, rain_event_id),

    # Markov Chain State
    rain_yesterday = lag(rain_today, n = 1)
  ) %>%
  ungroup() %>%
  # Remove rows lost to lagging (first 7 days)
  filter(!is.na(rain_yesterday), !is.na(rainfall_ma7)) %>%
  select(-rain_event_id) %>%
  mutate(
    # Cyclical Time Encoding
    # Preserves the proximity between Dec 31 and Jan 1
    day_of_year = yday(date),
    day_sin = sin(2 * pi * day_of_year / 365),
    day_cos = cos(2 * pi * day_of_year / 365),

    # Interaction Terms (The "Rain Corner")
    # Centering variables before interaction reduces multicollinearity
    sunshine = scale(sunshine, center = TRUE, scale = FALSE),
    humidity3pm = scale(humidity3pm, center = TRUE, scale = FALSE),
    sun_humid_interaction = as.numeric(sunshine * humidity3pm),

    # Meteorological Indices
    pressure_change = pressure3pm - pressure9am,
    dewpoint_9am = temp9am - ((100 - humidity9am) / 5),
    dewpoint_3pm = temp3pm - ((100 - humidity3pm) / 5),
    dewpoint_change = dewpoint_3pm - dewpoint_9am,
    moisture_index = humidity3pm * (1 - sunshine / 15),
    instability_index = (1020 - pressure3pm) * humidity3pm / 100,
    cloud_development = pmax(0, cloud3pm - cloud9am),

    # Circular Wind Vector Decomposition
    # Converts degrees (0-360) into continuous North-South (V) and East-West (U) vectors
    gust_rad = compass_lookup[wind_gust_dir] * pi / 180,
    gust_V_NS = wind_gust_speed * cos(gust_rad),
    gust_U_EW = wind_gust_speed * sin(gust_rad),
    wind9am_rad = compass_lookup[wind_dir9am] * pi / 180,
    wind9am_V_NS = wind_speed9am * cos(wind9am_rad),
    wind9am_U_EW = wind_speed9am * sin(wind9am_rad)
  ) %>%
  relocate(rain_today, date, location) %>%
  relocate(rain_yesterday, days_since_rain, .after = location) %>%
  relocate(ends_with("_ma7"), .after = days_since_rain) %>%
  relocate(day_sin, day_cos, .after = date)
```

Based on the statistical insights derived from the Exploratory Data Analysis, we implemented a targeted feature engineering pipeline to transform raw signals into predictive model inputs.

**1. Handling Seasonality (Cyclical Encoding):** Standard categorical months (1–12) fail to capture the proximity between December and January. To address the seasonal patterns identified in the seasonality section, we applied a sine/cosine transformation to the `day_of_year`.

-   **Result:** `day_sin` and `day_cos` provide a continuous, circular representation of time, allowing the model to "understand" that winter flows smoothly into spring.

**2. Capturing Persistence (Lagged Features):** The Markov Chain analysis proved that yesterday's weather is a strong predictor of today's.

-   **Leakage Prevention:** We explicitly `lag()` all moving averages (e.g., `rainfall_ma7`) by one day. This ensures that when predicting rain for *today*, the model only sees the 7-day trend ending *yesterday*.
-   **Dry Spells:** The `days_since_rain` counter captures the increasing "stickiness" of dry regimes identified in the dry spell analysis.

**3. Modeling Physical Interactions:** The "Rain Corner" visualization demonstrated that rain occurs specifically when high humidity coincides with low sunshine.

-   **Interaction Term:** We created `sun_humid_interaction` to mathematically represent this synergistic threshold.
-   **Centering:** Variables were centered prior to multiplication to minimize multicollinearity between the main effects and the interaction term.

**4. Vectorizing Wind Direction:** Wind direction is circular (360° is equal to 0°), which standard models misinterpret (treating 360 as "far" from 0).

-   **Decomposition:** We mapped compass directions to radians and decomposed them into **U (East-West)** and **V (North-South)** vector components. This allows the model to treat wind as a continuous physical force rather than an arbitrary category.

# Multicollinearity Diagnostics

```{r}
#| label: multicollinearity-check
#| echo: true
#| message: false
#| warning: false

# Feature Selection
# Exclude location and raw administrative columns to focus on meteorological drivers
df_wo_location <- select_model_features(df_final, keep_location = FALSE)

# Variance Inflation Factor (VIF) Check
# Diagnosing potential collinearity introduced by feature engineering
vif_results <- mc_check(df_wo_location)

# Display VIF Results
vif_results %>%
  as_tibble() %>%
  arrange(desc(VIF)) %>%
  kable(
    caption = "Variance Inflation Factor (VIF) for Selected Predictors",
    digits = 3
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# inal Scaling
# Applying Z-score standardization to the validated feature set
df_scaled <- df_wo_location %>% scale_data()
```

Following the creation of derived features (interactions, indices, and vector decompositions), it is imperative to verify that we have not introduced severe multicollinearity, which would destabilize the model coefficients. We utilized the Variance Inflation Factor (VIF) to diagnose these dependencies.

**Results Analysis:**

-   **Low to Moderate Collinearity (VIF \< 3):** The majority of our engineered features, including the cyclical time components (`day_sin`, `day_cos`) and the wind vector components (`gust_V_NS`, `gust_U_EW`), exhibit VIF values well below 3. This confirms that our decomposition strategy (e.g., separating wind speed/direction into U/V components) successfully preserved information without creating redundant signals.
-   **Interaction Stability:** The `sun_humid_interaction` term has a VIF of **1.25**, which is exceptionally low. This vindicates our decision to **center** the `sunshine` and `humidity3pm` variables before multiplication. Without centering, interaction terms often show VIFs \> 10 due to correlation with their main effects.
-   **High Collinearity (VIF \~ 5):** The highest VIF is observed for `humidity3pm` (**5.20**). This is expected, as this variable is structurally involved in multiple derived features (`moisture_index`, `instability_index`, `interaction`). However, a VIF of 5 is generally considered the upper threshold of acceptability (where VIF \> 10 indicates severe issues). Given that `humidity3pm` is the single strongest predictor of rainfall, we retain it, accepting this moderate inflation to preserve predictive power.

**Conclusion:** The feature set is numerically stable. The centering strategy effectively mitigated the risks associated with interaction terms, and the VIF values indicate that the model will be robust to coefficient variance.

# Modelling

## Establishing the Baseline (Null Model)

```{r}
#| label: null-model-fit
#| echo: true
#| message: false
#| eval: false

# Fit the Null Model (Intercept-Only)
# Establish a baseline AIC/BIC and recover global average parameters
# Using hurdle specification: binomial occurrence + truncated Gamma intensity
# Note: truncated_gamma() implements a hurdle model where:
#   - ziformula models the hurdle (probability of zero/occurrence)
#   - The Gamma component is truncated at zero (cannot generate zeros)
m0_null <- glmmTMB(
  formula = rainfall ~ 1, # Model rainfall intensity using only an intercept
  ziformula = ~1, # Model probability of dry days using only an intercept (hurdle component)
  family = truncated_gamma(link = "log"), # Truncated Gamma for positive rain (hurdle model)
  data = df_scaled
)
```

```{r}
#| label: null-model-output

tab_model(
  m0_null,
  show.se = TRUE,
  show.aic = TRUE,
  transform = "exp",
  collapse.se = TRUE,
  p.style = "numeric_stars",
  string.pred = "Parameter",
  string.est = "Estimate (Exp)",
  dv.labels = "Baseline Rainfall Model",
  title = "Table 1: Baseline Hurdle Gamma Model (Intercept Only)"
)
```

To quantify the value added by our meteorological predictors, we first fitted a **"Null" Hurdle Gamma model**. This model contains no predictors (covariates); it consists solely of intercepts. Its purpose is to verify if the model structure correctly recovers the fundamental properties of the dataset (the global probability of rain and the global average intensity).

**1. Hurdle Component (Occurrence):** The hurdle intercept is $\beta_{zi} = 0.5769$. Since this component uses a **logit** link function, we can back-transform it to find the baseline probability of a dry day:

$$P(\text{Dry}) = \frac{e^{0.5769}}{1 + e^{0.5769}} \approx \frac{1.78}{2.78} \approx 64.03\%$$

**Insight:** This model-derived probability matches the empirical occurrence rate ($64.05\%$) calculated in our EDA perfectly. This confirms the model is correctly calibrated to the frequency of dry days. In the hurdle framework, this component represents a true binomial process for rain occurrence.

**2. Conditional Component (Truncated Gamma Intensity):** The conditional intercept is $\beta_{cond} = 1.8825$. Using the **log** link function, we recover the baseline rainfall intensity for wet days:

$$\mu_{\text{rain}} = e^{1.8825} \approx 6.57 \text{ mm}$$

**Insight:** This represents the typical "geometric mean" rainfall intensity when it does rain, unadjusted for season or location. Importantly, the truncated Gamma specification ensures this component never generates zeros—all zeros are strictly modeled by the hurdle component, maintaining clear separation between occurrence and intensity processes.

**3. Performance Baseline:**

-   **AIC:** 461,669.7

-   **Implication:** Any subsequent model including predictors (e.g., `humidity`, `pressure`, `season`) must achieve an AIC significantly lower than this value to demonstrate predictive power.

## Moisture Dynamics

```{r}
#| label: m1-moisture-code
#| echo: true
#| eval: false

# Update the null model to include moisture-related predictors
m1_moisture <- update(
  m0_null,
  . ~ . + humidity3pm + dewpoint_9am + dewpoint_change + pressure_change,
  ziformula = ~ humidity3pm + dewpoint_9am
)
```

```{r}
#| label: m1-moisture-output
#| echo: false

m1_moisture %>%
  tbl_regression(
    exponentiate = TRUE,
    label = list(
      humidity3pm ~ "Humidity (3pm)",
      dewpoint_9am ~ "Dewpoint (9am)",
      dewpoint_change ~ "Dewpoint Change (Delta)",
      pressure_change ~ "Pressure Change (Delta)"
    )
  ) %>%
  bold_p() %>%
  add_glance_table(include = c("AIC", "BIC", "logLik")) %>%
  modify_header(label = "**Predictor**") %>%
  modify_caption("**Model 1: Moisture & Pressure Dynamics**")
```

Building upon the baseline, "Model 1" incorporates the primary moisture and pressure drivers identified in the exploratory analysis. Specifically, we test the hypothesis that atmospheric moisture content (`humidity`, `dewpoint`) and pressure stability (`pressure_change`) drive both the occurrence and intensity of rainfall.

**1. Performance Improvement:**

-   **AIC Reduction:** The AIC dropped dramatically from **461,669.7 (Null)** to **422,847 (M1)**.

-   **Significance:** This massive reduction ($\Delta AIC \approx 38,823$) confirms that moisture dynamics are foundational predictors, explaining a vast amount of the variance in the dataset.

**2. Conditional Model (Rainfall Intensity):** All predictors in the conditional part are statistically significant ($p < 2e^{-16}$):

-   **Humidity & Dewpoint:** Both `humidity3pm` ($\beta = 0.38$) and `dewpoint_9am` ($\beta = 0.38$) have strong positive effects. As the air becomes more saturated (higher humidity) and holds more absolute moisture (higher dewpoint), rainfall intensity increases.

-   **Pressure Change:** The coefficient is positive ($\beta = 0.23$), suggesting that larger rapid fluctuations in pressure (instability) correlate with heavier rainfall.

**3. Hurdle Model (Probability of Dry Days):**

-   **Humidity:** The coefficient for `humidity3pm` is **-1.07**. In a hurdle model, a *negative* coefficient means the predictor *decreases* the log-odds of a zero (dry day). Therefore, **higher humidity significantly increases the probability of rain**.

-   **Non-Significance:** Interestingly, `dewpoint_9am` is not significant in the hurdle part ($p = 0.907$). This implies that while the *absolute* moisture (dewpoint) determines *how hard* it rains (intensity, conditional on occurrence), it is the *relative* saturation (humidity) that determines *if* it rains at all. This clear separation is a strength of the hurdle specification.

## Temporal Dynamics and Persistence

```{r}
#| label: m2-temporal-code
#| echo: true
#| eval: false

# Update Model 1 to include:
# - Cyclical Seasonality (day_cos, day_sin) in the Conditional Model
# - Persistence (rain_yesterday) and Development (cloud/pressure) in the ZI Model
m2_temporal <- update(
  m1_moisture,
  . ~ . + day_cos + day_sin,
  ziformula = ~ humidity3pm +
    dewpoint_9am +
    rain_yesterday +
    cloud_development +
    pressure_change
)

```

```{r}
#| label: m2-temporal-output
#| echo: false

m2_temporal %>%
  tbl_regression(
    exponentiate = TRUE,
    label = list(
      day_cos ~ "Seasonality (Cos)",
      day_sin ~ "Seasonality (Sin)",
      rain_yesterday ~ "Rain Yesterday (Persistence)",
      cloud_development ~ "Cloud Development",
      pressure_change ~ "Pressure Change"
    )
  ) %>%
  bold_p() %>%
  add_glance_table(include = c("AIC", "BIC")) %>%
  modify_header(label = "**Predictor**") %>%
  modify_caption("**Model 2: Temporal & Persistence Effects**")
```

"Model 2" extends the analysis by incorporating the time-dependent structures identified in our EDA: **seasonality** (cyclical encoding) and **persistence** (Markov chains). We also refined the Hurdle component to include dynamic drivers like `cloud_development` and `pressure_change`.

**1. Performance Improvement:**

-   **AIC Reduction:** The model achieved an AIC of **406,659**, a substantial improvement over Model 1 (422,846).

-   **Magnitude:** The reduction of $\Delta AIC \approx 16,187$ confirms that adding temporal context (knowing *when* in the year and *what happened yesterday*) provides critical predictive information that moisture variables alone cannot capture.

**2. Conditional Model (Rainfall Intensity):**

-   **Seasonality:** Both `day_cos` ($\beta = 0.03, p < 0.001$) and `day_sin` ($\beta = -0.04, p < 0.001$) are highly significant. This mathematically confirms the "Summer Peak" pattern observed before, rainfall intensity is not constant but oscillates sinusoidally throughout the year.

-   **Robustness:** The coefficients for moisture (`humidity3pm`, `dewpoint`) remained stable compared to Model 1, indicating that seasonality is an independent driver of intensity, not just a proxy for changing humidity levels.

**3. Hurdle Model (Probability of Dry Days):**

-   **The "Persistence" Effect:** The strongest predictor in the hurdle model is `rain_yesterdayYes` with a coefficient of **-1.42**.

-   **Interpretation:** Because the Hurdle model predicts the probability of a *zero* (dry day), a negative coefficient means *lower odds of being dry*.

-   **Odds Ratio:** $\exp(-1.42) \approx 0.24$. This implies that if it rained yesterday, the odds of today being dry drop by \~76%. This is a massive effect size that validates the Markov Chain findings before.

-   **Dynamic Drivers:**

-   `pressure_change` ($\beta = -0.51$): Large pressure drops significantly decrease the probability of a dry day (i.e., increase rain probability).

-   `cloud_development` ($\beta = 0.11$): Surprisingly, positive cloud development (more clouds at 3pm than 9am) has a positive coefficient here, slightly *increasing* the hurdle probability (probability of a dry day). This might capture non-precipitating cumulus buildup typical of dry, fair-weather afternoons.

## Historical Context and Persistence

```{r}
#| label: m3-history-code
#| echo: true
#| eval: false

# Update Model 2 to include Historical Context in the Conditional Model
# - Rainfall Moving Average (7-day)
# - Days Since Last Rain (Drought effect)
# - Humidity Moving Average (7-day)
# - Rain Yesterday (Persistence on Intensity)
m3_history <- update(
  m2_temporal,
  . ~ . + rainfall_ma7 + days_since_rain + humidity_ma7 + rain_yesterday,
  ziformula = ~ humidity3pm +
    dewpoint_9am +
    rain_yesterday +
    cloud_development +
    pressure_change
)
```

```{r}
#| label: m3-history-output
#| echo: false

m3_history %>%
  tbl_regression(
    exponentiate = TRUE,
    label = list(
      rainfall_ma7 ~ "Rainfall Trend (7-Day MA)",
      humidity_ma7 ~ "Humidity Trend (7-Day MA)",
      days_since_rain ~ "Dry Spell Length (Days)",
      rain_yesterday ~ "Rain Yesterday (Indicator)"
    )
  ) %>%
  bold_p() %>%
  add_glance_table(include = c("AIC", "BIC")) %>%
  modify_header(label = "**Predictor**") %>%
  modify_caption("**Model 3: Historical Trends & Lagged Effects**")
```

"Model 3" integrates the final layer of complexity: **history**. While Model 2 accounted for *when* we are (seasonality), Model 3 accounts for *what just happened* (recent weather trends). We hypothesize that the intensity of today's rain is conditionally dependent on the saturation of the ground and atmosphere over the past week.

**1. Performance Improvement:**

-   **AIC Reduction:** The AIC improved to **404,936.2**, down from 406,659.3 (M2).

-   **Significance:** This reduction ($\Delta AIC \approx 1,723$) indicates that adding historical moving averages improves the model, though with diminishing returns compared to the massive leaps seen in Models 1 and 2.

**2. Conditional Model (Rainfall Intensity):**

-   **Persistence of Intensity (`rain_yesterday`):** The coefficient is positive ($\beta = 0.31, p < 0.001$). This implies that if it rained yesterday, today's rainfall is likely to be **\~37% more intense** ($e^{0.31} \approx 1.36$). Wet weather systems tend to be "heavy" and sustained.

-   **Accumulated Wetness (`rainfall_ma7`):** The positive coefficient ($\beta = 0.13$) confirms that a wetter preceding week correlates with heavier rainfall today, likely due to deep atmospheric moisture saturation.

-   **The "Drizzle" Effect (`humidity_ma7`):** Interestingly, the 7-day humidity average has a *negative* coefficient ($\beta = -0.10$). Once we control for *today's* humidity (which is positive), a persistently humid week might indicate stable, low-intensity stratiform clouds (drizzle) rather than the explosive instability required for heavy convective storms.

-   **Drought Effect (`days_since_rain`):** This variable is **not significant** ($p = 0.14$) for intensity. While our dry spell analysis showed it strongly predicts *whether* it rains (Hurdle component), it does not appear to influence *how much* it rains once the dry spell breaks.

**3. Hurdle Model:**

-   The coefficients remain robust and nearly identical to Model 2, reaffirming that `rain_yesterday` ($\beta = -1.42$) is the dominant driver of the state change from "Dry" to "Wet."

## Energy Dynamics and Interactions

```{r}
#| label: m4-energy-code
#| echo: true
#| eval: false

# Update Model 3 to include Energy Dynamics and Interactions
# - Sunshine & Evaporation (Energy Input)
# - Instability Index (Atmospheric Dynamics)
# - The "Rain Corner" Interaction (Sunshine * Humidity)
# - Cloud Development (Diurnal Change)
m4_energy <- update(
  m3_history,
  . ~ . +
    sunshine +
    evaporation +
    instability_index +
    sun_humid_interaction +
    cloud_development,
  ziformula = ~ humidity3pm +
    dewpoint_9am +
    rain_yesterday +
    cloud_development +
    pressure_change
)
```

```{r}
#| label: m4-energy-output
#| echo: false

m4_energy %>%
  tbl_regression(
    exponentiate = TRUE,
    label = list(
      sunshine ~ "Sunshine Duration (Hours)",
      evaporation ~ "Evaporation Rate",
      instability_index ~ "Instability Index (Derived)",
      sun_humid_interaction ~ "Interaction: Sun * Humid",
      cloud_development ~ "Cloud Development (Delta)"
    )
  ) %>%
  bold_p() %>%
  add_glance_table(include = c("AIC", "BIC")) %>%
  modify_header(label = "**Predictor**") %>%
  modify_caption("**Model 4: Thermodynamic Energy & Interactions**")
```

"Model 4" represents the full complexity of our meteorological hypothesis. Beyond moisture and history, we now incorporate **energy dynamics** (solar radiation, evaporation) and **atmospheric instability**. Crucially, we test the interaction term derived in the previous section to capture the non-linear "Rain Corner" effect.

**1. Performance Improvement:**

-   **AIC Reduction:** The AIC dropped to **403,051.8**.

-   **Significance:** The reduction of $\Delta AIC \approx 1,884$ compared to Model 3 confirms that including energy dynamics provides a statistically significant improvement in model fit.

**2. Conditional Model (Rainfall Intensity):**

-   **The "Rain Corner" Interaction:** The `sun_humid_interaction` term is highly significant ($\beta = -0.08, p < 0.001$).

-   **Interpretation:** The negative coefficient confirms the "corner" geometry. As sunshine increases, the positive effect of humidity on rainfall intensity is dampening. Conversely, the heaviest rain occurs when humidity is high *and* sunshine is low (deep cloud cover).

-   **Instability:** The `instability_index` has a strong positive effect ($\beta = 0.19$). This confirms that low-pressure, high-humidity systems (convective instability) produce significantly heavier rainfall than stable systems.

-   **Evaporation:** Surprisingly, `evaporation` has a positive coefficient ($\beta = 0.19$). While high evaporation typically implies dry heat, in the context of a wet day, it likely serves as a proxy for the **available energy** (latent heat) in the system that fuels storm development.

-   **Sunshine:** As expected, `sunshine` has a negative effect ($\beta = -0.07$) on intensity. Even if it rains on a sunny day (e.g., a brief shower), the intensity is lower compared to a fully overcast day.

**3. Shift in Humidity Importance:** Notice that the coefficient for `humidity3pm` dropped drastically from **0.39** (Model 3) to **0.08** (Model 4).

-   **Explanation:** This does *not* mean humidity is less important. Rather, the variance previously attributed to raw "humidity" has now been correctly partitioned into more specific physical processes: `instability_index` (pressure-humidity interaction) and `sun_humid_interaction`. The model now understands *why* humidity matters.

## Wind Dynamics

```{r}
#| label: m5-wind-code
#| echo: true
#| eval: false

# Update Model 4 to include Circular Wind Vectors
# - Gust U (East-West) and V (North-South) components
# - 9am Wind U and V components (Morning wind direction)
m5_wind <- update(
  m4_energy,
  . ~ . + gust_U_EW + gust_V_NS + wind9am_V_NS + wind9am_U_EW,
  ziformula = ~ humidity3pm +
    dewpoint_9am +
    rain_yesterday +
    cloud_development +
    pressure_change
)
```

```{r}
#| label: m5-wind-output
#| echo: false

m5_wind %>%
  tbl_regression(
    exponentiate = TRUE,
    label = list(
      gust_U_EW ~ "Gust Vector (East-West)",
      gust_V_NS ~ "Gust Vector (North-South)",
      wind9am_U_EW ~ "Wind 9am Vector (East-West)",
      wind9am_V_NS ~ "Wind 9am Vector (North-South)"
    )
  ) %>%
  bold_p() %>%
  add_glance_table(include = c("AIC", "BIC")) %>%
  modify_header(label = "**Predictor**") %>%
  modify_caption("**Model 5: Wind Vector Dynamics**")
```

"Model 5" introduces the final physical layer: **Wind Vector Decomposition**. By decomposing wind direction into North-South ($V$) and East-West ($U$) components, we test the hypothesis that specific airflow origins (e.g., moisture-laden ocean winds vs. dry desert winds) drive rainfall intensity.

**1. Performance Improvement:**

-   **AIC Reduction:** The AIC dropped to **402,452.7** from 403,051.8 (M4).

-   **Significance:** The decrease of $\Delta AIC \approx 600$ is smaller than previous steps but still highly statistically significant, confirming that wind direction adds unique information not captured by pressure or season alone.

**2. Conditional Model (Rainfall Intensity):** All wind vector components are statistically significant ($p < 0.001$), and their signs reveal a clear physical story consistent with Australian climatology:

-   **North-South Vector (`wind9am_V_NS`):** The coefficient is **-0.088**.
    -   *Mathematical interpretation:* Since $V > 0$ represents North (winds from the interior/equator) and $V < 0$ represents South (winds from the ocean), a **negative coefficient** implies that **Southerly winds (negative V)** increase rainfall intensity.
    -   *Physical validation:* This aligns perfectly with Australian geography, where "Southerly Busters" and fronts from the Southern Ocean bring cold, heavy rain, while Northerly winds typically bring dry heat from the desert interior.
-   **East-West Vector (`wind9am_U_EW`):** The coefficient is **-0.085**.
    -   *Interpretation:* A negative coefficient implies that **Westerly winds (negative U)** increase rainfall.
    -   *Physical validation:* This captures the "Roaring Forties" and the prevailing Westerlies that bring frontal rain systems to the southern continent.
-   **Gusts vs. Sustained Wind:** The morning winds (`wind9am`) have coefficients roughly 3-4x larger than the gust components (`gust_U/V`, $\beta \approx -0.02$). This suggests that the **prevailing air mass direction** (advection) is more important for determining rainfall volume than the localized turbulence of wind gusts.

**3. Model Stability:** Crucially, the coefficients for previous drivers (Humidity, Instability, Seasonality) remained stable. This indicates that our Wind Vectors are **orthogonal predictors**; they explain *new* variance rather than stealing explanatory power from existing features.

## Spatial Heterogenity (Mixed Effects)

```{r}
#| label: m6-mixed-code
#| echo: true
#| eval: false

# We explicitly keep 'location' to serve as the grouping factor
re_data <- select_model_features(df_final, keep_location = TRUE) %>%
  scale_data()

# Define Optimizer Control
# BFGS optimizer is selected for better convergence on complex GLMM surfaces
ctrl <- glmmTMBControl(
  optimizer = optim,
  optArgs = list(method = "BFGS"),
  optCtrl = list(maxit = 1000)
)

# 3. Fit Hurdle Gamma Mixed Model
# - Random Intercepts: (1 | location) -> Baseline rainfall varies by city
# - Random Slopes: (humidity + rain_yesterday... | location) -> The *effect* of these drivers varies by city
m6_mixed <- glmmTMB(
  rainfall ~
    humidity3pm +
    dewpoint_9am +
    dewpoint_change +
    pressure_change +
    day_cos +
    day_sin +
    rainfall_ma7 +
    days_since_rain +
    humidity_ma7 +
    rain_yesterday +
    sunshine +
    evaporation +
    instability_index +
    sun_humid_interaction +
    cloud_development +
    gust_U_EW +
    gust_V_NS +
    wind9am_V_NS +
    wind9am_U_EW +
    diag(1 + humidity3pm + rain_yesterday + dewpoint_change | location),
  ziformula = ~ humidity3pm +
    dewpoint_9am +
    rain_yesterday +
    cloud_development +
    pressure_change +
    rain_yesterday +
    sunshine +
    evaporation +
    ns(days_since_rain, df = 4) +
    humidity_ma7 +
    day_cos +
    day_sin,
  data = re_data,
  control = ctrl,
  family = truncated_gamma(link = "log")  # Hurdle model with truncated Gamma
)
```

```{r}
#| label: m6-mixed-output
#| echo: false

m6_mixed %>%
  tbl_regression(
    exponentiate = TRUE,
    label = list(
      # Core Dynamics
      humidity3pm ~ "Humidity (3pm)",
      sunshine ~ "Sunshine Duration",
      sun_humid_interaction ~ "Interaction: Sun * Humid",

      # Persistence & History
      rainfall_ma7 ~ "Rainfall Trend (7-Day MA)",
      days_since_rain ~ "Dry Spell Length (Linear)",
      `ns(days_since_rain, df = 4)` ~ "Dry Spell (Non-Linear Spline)",
      rain_yesterday ~ "Rain Yesterday (Indicator)",

      # Physics & Wind
      gust_U_EW ~ "Gust Vector (East-West)",
      gust_V_NS ~ "Gust Vector (North-South)",
      instability_index ~ "Instability Index",

      # Seasonality
      day_cos ~ "Seasonality (Cos)",
      day_sin ~ "Seasonality (Sin)"
    )
  ) %>%
  bold_p() %>%
  add_glance_table(include = c("AIC", "BIC", "logLik", "nobs")) %>%
  modify_header(label = "**Predictor**") %>%
  modify_caption(
    "**Model 6: The Final Mixed-Effects Model (Random Slopes)**"
  ) %>%
  as_gt() %>%
  gt::tab_footnote(
    footnote = "Random Effects Structure: Uncorrelated random slopes for Humidity, Persistence, and Dewpoint by Location."
  )
```

The final stage of our modeling strategy addresses the hierarchical nature of the data. Meteorological phenomena are not spatially uniform; the physics of rainfall in a tropical city like Cairns differs from that in an arid city like Alice Springs. To capture this, "Model 6" introduces **Random Effects**, allowing the model parameters to vary by `location`.

**1. Performance Improvement:**

-   **AIC Reduction:** The AIC plummeted to **394,854.0**.

-   **Significance:** This represents a massive improvement ($\Delta AIC \approx 7,599$) over the best fixed-effects model (M5). This confirms that **spatial heterogeneity** is a dominant source of variance. A global "one-size-fits-all" model is insufficient for continental-scale weather prediction.

**2. Random Effects Structure (Variance Components):** We incorporated random intercepts and random slopes for key drivers. The estimated variances reveal significant local differences:

-   **Random Intercepts (**$\sigma^2 = 0.12$): Baseline rainfall intensity varies significantly between locations, confirming that local geography sets the "default" weather state.

-   **Random Slope - Humidity (**$\sigma^2 = 0.023$): The effect of humidity on rainfall is not constant. In some locations, a small increase in humidity triggers rain (high sensitivity), while in others, the atmosphere requires much higher saturation (low sensitivity).

-   **Random Slope - Persistence (**$\sigma^2 = 0.013$): The "stickiness" of wet weather (`rain_yesterday`) varies spatially, likely driven by the difference between stagnation-prone valleys and wind-swept coastal plains.

**3. Fixed Effects Stability:** Despite allowing for local variation, the global fixed effects (Wind Vectors, Instability, Interactions) remained highly significant.

-   **Wind Vectors:** Both `wind9am_V_NS` ($\beta = -0.086$) and `wind9am_U_EW` ($\beta = -0.064$) retained their negative coefficients. This proves that the influence of Southerly and Westerly winds is a robust, continent-wide driver, not an artifact of a few specific locations.

-   **The "Rain Corner":** The interaction term `sun_humid_interaction` ($\beta = -0.067$) remains significant, validating the non-linear relationship between energy and moisture across all Australian climates.

**4. Hurdle Component & Splines:**

-   The inclusion of **Natural Splines** (`ns(days_since_rain, df=4)`) in the hurdle formula allows the probability of a dry spell ending to vary non-linearly over time. The significance of the second spline term ($p = 0.018$) suggests that the "drying effect" is not a simple linear decay, capturing the complex "kink" observed in our dry spell survival plots.

# Model Evaluation

## Classification Performance Evaluation

```{r}
#| label: model-evaluation
#| echo: true
#| fig-cap: "ROC Curve for Rainfall Occurrence Prediction. An AUC of 0.83 indicates strong discriminative ability, effectively separating dry days from wet days."
#| message: false
#| warning: false
re_data <- select_model_features(df_final, keep_location = TRUE) %>%
  scale_data()
# Generate Probabilities
# Extract the probability of "Structural Zero" (No Rain) from the Hurdle Model
prob_no_rain <- predict(m6_mixed, type = "zprob")

# Define Ground Truth (1 = No Rain, 0 = Rain)
actual_no_rain <- ifelse(re_data$rainfall == 0, 1, 0)

# ROC Curve Analysis
roc_obj <- roc(actual_no_rain, prob_no_rain)

plot(
  roc_obj,
  main = "ROC Curve: Predicting Rainfall Occurrence",
  col = "#0072B2",
  lwd = 2,
  print.auc = TRUE,
  print.auc.y = 0.4
)

# Threshold Optimization (Youden's J)
# Find the cut-off that balances Sensitivity (catching rain) and Specificity (catching dry days)
coords_obj <- coords(roc_obj, "best", best.method = "youden")
optimal_threshold <- coords_obj$threshold

cat(sprintf("\nOptimal Probability Threshold: %.4f\n", optimal_threshold))

# Confusion Matrix & Accuracy
predicted_class <- ifelse(prob_no_rain > optimal_threshold, "No Rain", "Rain")
actual_class <- ifelse(re_data$rainfall == 0, "No Rain", "Rain")

conf_matrix <- table(Predicted = predicted_class, Actual = actual_class)

conf_matrix %>%
  kable(caption = "Confusion Matrix (Optimal Threshold)") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

# Calculate Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat(sprintf("\nModel Accuracy: %.2f%%\n", accuracy * 100))
```

While the Gamma component of our model estimates rainfall *amount* conditional on occurrence, the Hurdle component acts as a binary classifier answering the fundamental question: *"Will it rain?"*. We evaluated this classification performance using the Receiver Operating Characteristic (ROC) curve and Confusion Matrix.

**1. Discriminative Power (AUC):** The model achieves an **Area Under the Curve (AUC) of 0.832** .

-   **Interpretation:** This indicates a strong predictive capability. In 83.2% of randomly selected pairs (one wet day, one dry day), the model correctly assigns a higher probability of dryness to the actual dry day.

-   **Significance:** This confirms that our engineered features (particularly `rain_yesterday` and `pressure_change`) provide a robust signal for distinguishing weather states.

**2. Optimal Thresholding:** Standard models default to a 50% probability cutoff. However, using Youden’s J statistic, we identified the optimal decision threshold as **0.645**.

-   **Implication:** Because dry days are the majority class (64%), the model requires a higher certainty (\>64.5% probability) before confidently predicting "No Rain." This adjustment maximizes the balance between catching rain events and avoiding false alarms.

**3. Confusion Matrix Analysis:** At this optimal threshold, the model demonstrates:

-   **Accuracy:** **75.41%** overall correctness.

-   **Sensitivity vs. Specificity:**

-   **Correct Dry Predictions (TN):** 68,544 days.

-   **Correct Rain Predictions (TP):** 38,433 days.

-   **False Alarms (Type I Error):** 22,294 days were predicted to rain but stayed dry.

-   **Missed Rain (Type II Error):** 12,585 days were predicted dry but actually rained.

**Conclusion:** The model is conservative; it is twice as likely to raise a "False Alarm" (predict rain that doesn't happen) than to miss a rain event. In a meteorological context, this is often desirable;it is better to carry an umbrella and not need it than to be caught in a storm unprepared.

## Random Effects Visualization

```{r}
#| label: fig-location-effects
#| fig-cap: "The Geography of Rain: Random Intercepts by Location. This 'Caterpillar Plot' shows the baseline rainfall adjustment for each city. Cities in blue (e.g., Katherine, Darwin) have inherently heavier rainfall than the national average, while cities in red (e.g., Nhil, Norfolk Island) are inherently drier, even after controlling for humidity, pressure, and season."
#| fig-width: 10
#| fig-height: 12
#| echo: true
#| warning: false

# Extract Random Effects
ranef_data <- ranef(m6_mixed)

# Process for Plotting
loc_effects <- as.data.frame(ranef_data$cond$location) %>%
  rownames_to_column("Location") %>%
  rename(Effect = `(Intercept)`) %>%
  arrange(Effect) %>%
  mutate(
    Location = factor(Location, levels = Location),
    # Approximate Confidence Intervals
    CI_lower = Effect - 1.96 * sd(Effect) / sqrt(n()),
    CI_upper = Effect + 1.96 * sd(Effect) / sqrt(n()),
    Category = case_when(
      Effect > sd(Effect) ~ "Significantly Wetter",
      Effect < -sd(Effect) ~ "Significantly Drier",
      TRUE ~ "Near Average"
    ),
    Category = factor(
      Category,
      levels = c("Significantly Drier", "Near Average", "Significantly Wetter")
    )
  )

# Generate Caterpillar Plot
ggplot(loc_effects, aes(x = Effect, y = Location)) +
  # Background Shading for Significance Zones
  annotate(
    "rect",
    xmin = -Inf,
    xmax = -sd(loc_effects$Effect),
    ymin = -Inf,
    ymax = Inf,
    fill = "#c0392b",
    alpha = 0.05
  ) +
  annotate(
    "rect",
    xmin = sd(loc_effects$Effect),
    xmax = Inf,
    ymin = -Inf,
    ymax = Inf,
    fill = "#2980b9",
    alpha = 0.05
  ) +
  geom_vline(
    xintercept = 0,
    linetype = "dashed",
    color = "grey30",
    linewidth = 0.8
  ) +
  geom_vline(
    xintercept = c(-sd(loc_effects$Effect), sd(loc_effects$Effect)),
    linetype = "dotted",
    color = "grey50",
    linewidth = 0.5
  ) +
  geom_segment(
    aes(
      x = CI_lower,
      xend = CI_upper,
      y = Location,
      yend = Location,
      color = Category
    ),
    linewidth = 1.5,
    alpha = 0.4
  ) +
  geom_point(aes(color = Category), size = 4, alpha = 0.9) +
  geom_text(
    data = filter(loc_effects, abs(Effect) > sd(Effect)),
    aes(
      label = sprintf("%.2f", Effect),
      x = Effect,
      hjust = ifelse(Effect > 0, -0.3, 1.3)
    ),
    size = 3,
    fontface = "bold",
    color = "grey20"
  ) +
  scale_color_manual(
    values = c(
      "Significantly Drier" = "#c0392b",
      "Near Average" = "#7f8c8d",
      "Significantly Wetter" = "#2980b9"
    ),
    name = "Effect Size"
  ) +
  labs(
    title = "The Geography of Rain: Location-Specific Baselines",
    subtitle = "Random intercepts show how much wetter/drier each city is, holding all weather variables constant.\nBars show 95% confidence intervals; points beyond +-1 SD are labeled.",
    x = "Baseline Rainfall Adjustment (Log mm)",
    y = NULL,
    caption = "Interpretation: A value of +0.5 means ~65% more rain than average location with identical conditions [exp(0.5) ≈ 1.65]"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid.major.y = element_line(color = "grey90", linewidth = 0.3),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_line(color = "grey90", linewidth = 0.3),
    plot.title = element_text(face = "bold", size = 16, margin = margin(b = 5)),
    plot.subtitle = element_text(
      color = "grey30",
      size = 11,
      margin = margin(b = 15)
    ),
    plot.caption = element_text(
      color = "grey50",
      size = 9,
      hjust = 0,
      margin = margin(t = 10)
    ),
    axis.text.y = element_text(size = 10, face = "bold"),
    axis.text.x = element_text(size = 10),
    axis.title.x = element_text(
      size = 11,
      face = "bold",
      margin = margin(t = 10)
    ),
    legend.position = "top",
    legend.justification = "left",
    legend.title = element_text(face = "bold", size = 10),
    legend.text = element_text(size = 9),
    plot.margin = margin(15, 15, 15, 15)
  )
```

To visualize the spatial heterogeneity captured by Model 6, we extracted the conditional modes (Random Intercepts) for all 49 locations . This plot reveals the inherent "wetness" or "dryness" of a city, **holding all dynamic weather variables constant**.

**1. The Tropical Top End (Wetter):** The cities with the highest positive adjustments are **Katherine (**$\beta = 0.59$) and **Darwin (**$\beta = 0.54$).

-   **Interpretation:** Even if Katherine and Melbourne experience the exact same humidity, pressure, and wind conditions, Katherine will produce significantly heavier rainfall ($e^{0.59} \approx 1.8x$ baseline). This captures the unmeasured convective potential of the Australian tropics.

**2. The Arid Interior and South (Drier):** At the bottom of the chart, we find **Nhil (**$\beta = -0.73$) and **Norfolk Island (**$\beta = -0.65$).

-   **Interpretation:** These locations have a "suppressive" geography. A weather system that would produce moderate rain elsewhere produces only light rain here.

**3. Significance:** The clear separation of locations into "Significantly Wetter" (Blue) and "Significantly Drier" (Red) zones validates the necessity of the Mixed Model. A standard regression model would have averaged these extremes, under-predicting flood risks in Darwin and over-predicting rainfall in the arid interior.

## Validating Model Assumptions

```{r}
#| label: model-diagnostics
#| echo: true
#| fig-cap: "DHARMa Residual Diagnostics for Model 6. Left: Q-Q plot of residuals shows excellent alignment with the expected uniform distribution (red line), indicating the Gamma distribution is an appropriate choice. Right: Residuals vs. Predicted plot shows no fanning or curvature, confirming homoscedasticity."
#| fig-width: 10
#| fig-height: 5
#| message: false
#| warning: false
#| cache: true
#| dependson: "global-setup"
# Simulate Residuals
res <- simulateResiduals(m6_mixed)

# Diagnostic Plots (Q-Q and Residual vs Predicted)
plot(res)

# Test for Over/Under-Dispersion
testDispersion(res)

# Test for Hurdle Calibration
testZeroInflation(res)
```

A complex model is only as good as its residuals. We utilized the **DHARMa** package to perform simulation-based diagnostics, which are superior to standard residual plots for Hurdle GLMMs.

**1. Q-Q Plot (Distributional Fit):** The Q-Q plot demonstrates a near-perfect alignment along the 1:1 diagonal.

-   **Result:** The Kolmogorov-Smirnov test indicates a significant deviation ($p < 0.05$), which is common in datasets of this magnitude ($N > 140,000$). However, visually, the deviations are negligible.

-   **Implication:** This confirms that the **Gamma distribution** correctly characterizes the positive rainfall values, capturing the skewness without systematic bias.

**2. Residuals vs. Predicted (Homoscedasticity):** The plot on the right shows a uniform spread of residuals across the range of predicted values.

-   **Quantile Lines:** The red quantile lines (25th, 50th, 75th) are straight and horizontal, indicating **no significant non-linearity or heteroscedasticity**. The model performs equally well for light drizzle and heavy storms.

**3. Formal Tests:**

-   **Dispersion Test:** The non-parametric dispersion test yields a p-value of **0.192** .

-   **Interpretation:** We fail to reject the null hypothesis of ideal dispersion. This is a major victory for the model, confirming that the `truncated_gamma` family successfully handled the variance structure without over-dispersion.

-   **Hurdle Calibration Test:** The test compares the observed zeros to the simulated zeros.

-   **Ratio:** The ratio of observed to simulated zeros is **1.00** ($p = 0.992$).

-   **Interpretation:** The model predicts the *exact* correct number of dry days. The Hurdle component is perfectly calibrated to the occurrence process.

**Conclusion:** Model 6 passes all critical diagnostic checks. It is robust, well-calibrated, and valid for inference.

## Verifying Temporal Independence

```{r}
#| label: temporal-autocorrelation
#| echo: true
#| fig-cap: "Temporal Autocorrelation Check (Canberra). Left: Residuals vs. Time showing random scatter. Right: Autocorrelation Function (ACF) plot showing lags falling within the blue confidence bounds, confirming independence."
#| message: false
#| warning: false

# Align Residuals with Time Series
# Extract the exact rows used in the model
rows_used <- as.numeric(rownames(m6_mixed$frame))

# Filter for a single continuous time series (Canberra)
Canberra_data <- df_final[rows_used, ] %>%
  mutate(dharma_resid = residuals(res)) %>%
  filter(location == "Canberra") %>%
  arrange(date)

# 2. Durbin-Watson Test
# Tests H0: Residuals are not autocorrelated (Independence)
dw_result <- testTemporalAutocorrelation(
  simulationOutput = Canberra_data$dharma_resid,
  time = Canberra_data$date
)

print(dw_result)
```

A critical assumption of Generalized Linear Mixed Models is that residuals are independent. In time-series data like weather, this is often violated by serial autocorrelation (e.g., if the model under-predicts today, it likely under-predicts tomorrow). We tested this assumption on the Canberra time series using the Durbin-Watson test.

**1. Durbin-Watson Statistic:** The test yielded a **DW statistic of 2.0406**.

-   **Benchmark:** A value of **2.0** indicates perfect independence (white noise). Values approaching 0 indicate positive autocorrelation, while values approaching 4 indicate negative autocorrelation.

-   **Result:** Our result is nearly indistinguishable from the ideal value of 2.0.

**2. Statistical Significance:** The p-value is **0.2355** ($> 0.05$).

-   **Conclusion:** We fail to reject the null hypothesis of independence. There is **no evidence of temporal autocorrelation** remaining in the residuals.

**3. Visual Confirmation:** The Autocorrelation Function (ACF) plot confirms this numerically.

-   **ACF Lags:** The vertical bars (correlations at Lag 1, Lag 2, etc.) all fall comfortably within the blue dashed confidence intervals.

-   **Implication:** This validates our feature engineering strategy. By explicitly including "History" terms;specifically the Markov chain (`rain_yesterday`) and the Dry Spell Spline (`days_since_rain`);we successfully "bleached" the temporal signal from the data. The model has fully learned the time-dependent patterns, leaving behind only random, independent noise.

## Predictive Accuracy and Generative Validity

```{r}
#| label: ppc-and-metrics
#| echo: true
#| fig-cap: "Posterior Predictive Check. The blue line represents the observed distribution of daily rainfall. The gray lines represent 50 simulated datasets generated by the model. The tight overlap confirms that the model correctly captures the heavy skew and structural zeros of the real climate system through its hurdle specification."
#| fig-width: 10
#| fig-height: 7
#| message: false
#| warning: false

# Calculate Prediction Error Metrics
# Generate point predictions (mean of the gamma distribution * probability of rain)
df_final$pred_rainfall <- predict(m6_mixed, type = "response")

# RMSE: Penalizes large errors (e.g., missing a cyclone)
global_rmse <- sqrt(mean((df_final$rainfall - df_final$pred_rainfall)^2))
# MAE: The average "miss" in millimeters
global_mae <- mean(abs(df_final$rainfall - df_final$pred_rainfall))

print(paste("Global RMSE:", round(global_rmse, 3), "mm"))
print(paste("Global MAE:", round(global_mae, 3), "mm"))

```

```{r}
#| label: pcc-simulation
#| eval: false

# Posterior Predictive Check (PPC)
# Does the model generate realistic data?
set.seed(123)
sims <- simulate(m6_mixed, nsim = 1000)
# Sample 50 simulations for visualization clarity
subset_sims <- sims[, sample(ncol(sims), 50)]
ppc_data <- bind_cols(
  Observed = re_data$rainfall,
  subset_sims
) %>%
  pivot_longer(
    cols = -Observed,
    names_to = "Simulation",
    values_to = "Simulated_Value"
  )
```

```{r}
#| label: plot-ppc
#| warning: false
#| message: false

ggplot() +
  # Simulated Worlds (Gray)
  geom_density(
    data = ppc_data,
    aes(x = Simulated_Value, group = Simulation),
    color = "gray70",
    size = 0.5,
    alpha = 0.5
  ) +
  # Real World (Blue)
  geom_density(
    data = re_data,
    aes(x = rainfall),
    color = "#0072B2",
    size = 1.2
  ) +
  coord_cartesian(xlim = c(-1, 20)) +
  labs(
    title = "Posterior Predictive Check",
    subtitle = "Does the model's imagination (Gray) match reality (Blue)?",
    x = "Rainfall (mm)",
    y = "Density"
  ) +
  theme_minimal()
```

To conclude the validation, we assessed the model's performance in absolute terms (Millimeters of Rain) and its generative capacity (Posterior Predictive Check).

**1. Error Metrics:**

-   **Global MAE (Mean Absolute Error): 2.71 mm.**

-   *Interpretation:* On any given day, our model’s prediction is, on average, within **2.7mm** of the actual rainfall. Given the high variance of Australian weather, this indicates a high degree of precision for day-to-day forecasting.

-   **Global RMSE (Root Mean Square Error): 7.48 mm.**

-   *Interpretation:* RMSE is more sensitive to outliers. The higher value here reflects the inherent unpredictability of extreme storm events (e.g., receiving 150mm when 50mm was predicted).

**2. Posterior Predictive Check (PPC):** The density plot answers the question: *If we simulated Australian weather using only our model equations, would it look real?*

-   **The Fit:** The blue line (Reality) sits perfectly nested within the bundle of gray lines (Model Simulations).

-   **Structural Zeros:** The peak at 0mm is captured accurately, confirming the Hurdle component is working properly to model occurrence.

-   **The Tail:** The decay rate (how quickly light rain turns into heavy rain) matches perfectly. A standard Gaussian model would have failed here, likely predicting negative rain or missing the heavy skew.

-   **Conclusion:** The model is not just fitting means; it is successfully replicating the underlying statistical distribution of the climate system.

## Justification of Distributional choice

```{r}
#| label: distribution-check-code
#| echo: true
#| eval: false

# Fit comparison models to test distributional assumptions

# Gaussian (Linear Regression)
# Assumes residuals are normally distributed (Bad for zero-heavy data)
m_linear <- glmmTMB(
  rainfall ~ humidity3pm +
    dewpoint_9am +
    dewpoint_change +
    pressure_change +
    day_cos +
    day_sin +
    rainfall_ma7 +
    days_since_rain +
    humidity_ma7 +
    rain_yesterday +
    sunshine +
    evaporation +
    instability_index +
    sun_humid_interaction +
    cloud_development +
    gust_U_EW +
    gust_V_NS +
    wind9am_V_NS +
    wind9am_U_EW +
    (1 | location),
  data = re_data,
  family = gaussian(link = "identity")
)

# Tweedie
# Handles zeros and positive skew automatically using a power variance parameter (1<p<2)
m_tweedie <- glmmTMB(
  rainfall ~ humidity3pm +
    dewpoint_9am +
    dewpoint_change +
    pressure_change +
    day_cos +
    day_sin +
    rainfall_ma7 +
    days_since_rain +
    humidity_ma7 +
    rain_yesterday +
    sunshine +
    evaporation +
    instability_index +
    sun_humid_interaction +
    cloud_development +
    gust_U_EW +
    gust_V_NS +
    wind9am_V_NS +
    wind9am_U_EW +
    (1 | location),
  data = re_data,
  family = tweedie(link = "log")
)
```

```{r}
#| label: fig-distribution-comparison
#| fig-cap: "Why Distribution Matters: Comparing Predictive Densities. The Gaussian model (Red) fails catastrophically by predicting negative rainfall (x < 0). The Hurdle Gamma (Blue) and Tweedie (Green) models correctly capture the zero-bound and the long right tail of the actual data (Black Dashed Line)."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

# Plot the density of predictions against the ground truth
check_data %>%
  select(rainfall, pred_linear, pred_tweedie, pred_zig) %>%
  pivot_longer(
    cols = -rainfall,
    names_to = "Model",
    values_to = "Prediction"
  ) %>%
  mutate(
    Model = dplyr::recode(
      Model,
      pred_linear = "Linear (Gaussian)",
      pred_tweedie = "Tweedie",
      pred_zig = "Hurdle Gamma (Ours)"
    )
  ) %>%
  ggplot(aes(x = Prediction, fill = Model)) +
  geom_density(alpha = 0.5) +
  # Ground Truth Overlay (Real Data)
  geom_density(
    aes(x = rainfall),
    fill = NA,
    color = "black",
    linetype = "dashed",
    size = 1
  ) +
  facet_wrap(~Model, scales = "free") +
  coord_cartesian(xlim = c(-5, 20)) +
  labs(
    title = "Why Distribution Matters",
    subtitle = "Black Dashed Line = REAL Data. \nNotice Linear predicts impossible negative rain. Tweedie/ZIG capture the shape.",
    x = "Predicted Rainfall (mm)",
    y = "Density"
  ) +
  theme_minimal()
```

Scientific modeling often faces a trade-off between simplicity and accuracy. To justify the complexity of our chosen **Hurdle Gamma** framework, we benchmarked it against a standard **Gaussian (Linear)** model and a **Tweedie** model.

**1. The Failure of Linearity (Gaussian):** The left panel of @fig-distribution-comparison illustrates the catastrophic failure of standard linear regression.

-   **The "Negative Rain" Problem:** The Gaussian model (Pink) assumes a symmetric bell curve errors. To fit the mean correctly, it is forced to predict significant amounts of **negative rainfall** (values $< 0$), which is physically impossible.

-   **Poor Tail Fit:** It completely fails to capture the long right tail of extreme storm events, under-predicting flood risks.

**2. Tweedie vs. Hurdle Gamma:** Both the Tweedie (Green) and our Hurdle Gamma (Blue) models successfully respect the physical boundary of zero rainfall. They both align closely with the black dashed line (Real Data).

-   **Why Hurdle Gamma?** While Tweedie is efficient, it uses a single process to model both the *probability* of rain and the *intensity*. Our analysis in (Markov Chains Analysis) proved that the drivers of rain *occurrence* (e.g., `pressure_change`) differ slightly from the drivers of *intensity* (e.g., `wind_vectors`).

-   **Conclusion:** The **Hurdle Gamma** was the superior choice because it allowed us to model these two distinct meteorological processes separately—using a Logit model for the "Dry" state and a truncated Gamma model for the "Wet" state—resulting in highly accurate, physically interpretable predictions. The strict truncation ensures the Gamma component never generates zeros, maintaining clear separation between occurrence and intensity.

# Final Model Selection and Variance Analysis

```{r}
#| label: model-progression-lrt
#| echo: true
#| message: false
#| warning: false

# Likelihood Ratio Tests (LRT)
# Test each progressive addition to ensure it adds significant explanatory power
lrt_1v0 <- lmtest::lrtest(m0_null, m1_moisture)
lrt_2v1 <- lmtest::lrtest(m1_moisture, m2_temporal)
lrt_3v2 <- lmtest::lrtest(m2_temporal, m3_history)
lrt_4v3 <- lmtest::lrtest(m3_history, m4_energy)
lrt_5v4 <- lmtest::lrtest(m4_energy, m5_wind)
lrt_6v5 <- lmtest::lrtest(m5_wind, m6_mixed)

# Compile Results Table
lrt_results <- tibble(
  Comparison = c(
    "Null vs Moisture",
    "Moisture vs Temporal",
    "Temporal vs History",
    "History vs Energy",
    "Energy vs Wind",
    "Wind vs Mixed Effects"
  ),
  Chi_square = c(
    lrt_1v0$Chisq[2],
    lrt_2v1$Chisq[2],
    lrt_3v2$Chisq[2],
    lrt_4v3$Chisq[2],
    lrt_5v4$Chisq[2],
    lrt_6v5$Chisq[2]
  ),
  df = c(
    lrt_1v0$Df[2],
    lrt_2v1$Df[2],
    lrt_3v2$Df[2],
    lrt_4v3$Df[2],
    lrt_5v4$Df[2],
    lrt_6v5$Df[2]
  ),
  raw_p = c(
    lrt_1v0$`Pr(>Chisq)`[2],
    lrt_2v1$`Pr(>Chisq)`[2],
    lrt_3v2$`Pr(>Chisq)`[2],
    lrt_4v3$`Pr(>Chisq)`[2],
    lrt_5v4$`Pr(>Chisq)`[2],
    lrt_6v5$`Pr(>Chisq)`[2]
  )
) %>%
  mutate(
    adj_p_value = p.adjust(raw_p, method = "holm"),
    Significant = ifelse(adj_p_value < 0.001, "***", 
                        ifelse(adj_p_value < 0.01, "**",
                              ifelse(adj_p_value < 0.05, "*", "ns"))),
    AIC_improvement = c(
      AIC(m0_null) - AIC(m1_moisture),
      AIC(m1_moisture) - AIC(m2_temporal),
      AIC(m2_temporal) - AIC(m3_history),
      AIC(m3_history) - AIC(m4_energy),
      AIC(m4_energy) - AIC(m5_wind),
      AIC(m5_wind) - AIC(m6_mixed)
    )
  )

lrt_results %>%
  mutate(
    Chi_square = round(Chi_square, 2),
    AIC_improvement = round(AIC_improvement, 1)
  ) %>%
  kable(caption = "Likelihood Ratio Tests: Progressive Model Building") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

```{r}
#| label: tbl-model-selection
#| tbl-cap: "Model Selection Table"
#| echo: true

model_selection <- tibble(
  Model = c(
    "m0_null",
    "m1_moisture",
    "m2_temporal",
    "m3_history",
    "m4_energy",
    "m5_wind",
    "m6_mixed"
  ),
  AIC = c(
    AIC(m0_null),
    AIC(m1_moisture),
    AIC(m2_temporal),
    AIC(m3_history),
    AIC(m4_energy),
    AIC(m5_wind),
    AIC(m6_mixed)
  ),
  BIC = c(
    BIC(m0_null),
    BIC(m1_moisture),
    BIC(m2_temporal),
    BIC(m3_history),
    BIC(m4_energy),
    BIC(m5_wind),
    BIC(m6_mixed)
  )
) %>%
  mutate(
    Delta_AIC = AIC - min(AIC),
    AIC_weight = exp(-0.5 * Delta_AIC) / sum(exp(-0.5 * Delta_AIC))
  ) %>%
  arrange(AIC)

model_selection %>%
  mutate(across(where(is.numeric), ~ round(., 2))) %>%
  kable(caption = "Model Selection Table") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

```{r}
#| label: fig-model-selection
#| fig-cap: "Model Selection: Progressive Improvement. The AIC drops significantly at every stage, confirming that no step was redundant. The largest jump occurs when adding basic moisture variables, but the addition of Spatial Mixed Effects (M6) also provides a massive improvement over the Wind model (M5)."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| message: false

ggplot(
  model_selection,
  aes(
    x = factor(
      Model,
      levels = c(
        "m6_mixed",
        "m5_wind",
        "m4_energy",
        "m3_history",
        "m2_temporal",
        "m1_moisture",
        "m0_null"
      )
    ),
    y = AIC
  )
) +
  geom_point(size = 4, color = "#0072B2") +
  geom_line(aes(group = 1), size = 1, color = "#0072B2", alpha = 0.5) +
  geom_hline(
    yintercept = min(model_selection$AIC),
    linetype = "dashed",
    color = "red"
  ) +
  geom_text(
    aes(label = sprintf("delta=%.0f", Delta_AIC)),
    vjust = -1,
    size = 3.5,
    fontface = "bold"
  ) +
  labs(
    title = "Model Selection: Progressive Improvement",
    subtitle = "Each step significantly improves fit (LRT p < 0.001 for all comparisons)",
    x = "Model (Ordered by Complexity)",
    y = "AIC (Lower is Better)",
    caption = "Red line = Best Model (M6 Mixed)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
    plot.title = element_text(face = "bold")
  )
```

```{r}
#| label: model-r2
#| echo: true
#| collapse: true

# Random Effects Necessity Test (LRT M5 vs M6)
re_test <- lmtest::lrtest(m5_wind, m6_mixed)
print(re_test)

# Nakagawa's R-Squared
# Decomposes variance into Fixed Effects (Marginal) vs. Random Effects (Conditional)
r2_vals <- performance::r2_nakagawa(m6_mixed)

cat(sprintf("\nMarginal R2 (Fixed Effects only): %.4f\n", r2_vals$R2_marginal))
cat(sprintf(
  "Conditional R2 (Fixed + Random Effects): %.4f\n",
  r2_vals$R2_conditional
))
```

We employed a strict forward-selection strategy, verifying that each additional layer of complexity provided statistically significant information gain.

**1. Progressive Improvement:** As shown in @fig-model-selection , the AIC decreased monotonically with every model update.

-   **Largest Gain:** The shift from Null to M1 (Moisture) reduced AIC by \~38,000, confirming that humidity is the primary driver.

-   **Final Gain:** The shift from M5 (Wind) to M6 (Mixed) reduced AIC by \~7,600. This is a massive improvement for a late-stage addition, proving that **spatial heterogeneity** is not a minor nuisance but a fundamental component of the Australian climate system.

**2. Likelihood Ratio Tests:** The formal LRT table confirms that every comparison yielded a p-value $< 0.001$. Even the smallest step (Wind Vectors, M5) improved the model significantly ($\chi^2 = 607, df=4$), justifying the inclusion of compass-based predictors.

**3. Variance Explained (**$R^2$): Using Nakagawa’s method for Generalized Linear Mixed Models:

-   **Marginal** $R^2 = 0.345$: Our fixed meteorological predictors (Humidity, Wind, Pressure, etc.) explain **34.5%** of the variance in rainfall intensity.

-   **Conditional** $R^2 = 0.441$: When we include the location-specific random effects, the explanatory power jumps to **44.1%**.

-   **Insight:** Roughly **10% of the explainable variance** in Australian rainfall is purely geographic;attributable to the specific location of the city (e.g., coastal vs. inland) rather than dynamic weather variables.

**Conclusion:** Model 6 (Mixed Effects Hurdle Gamma) is the statistically superior model. It maximizes likelihood, minimizes information loss (AIC/BIC), and captures significant spatial variance that fixed-effects models miss. The hurdle specification provides clear separation between occurrence and intensity processes, improving both interpretability and physical validity.

# Conclusion

## Summary of Findings

This study successfully developed a hierarchical Hurdle Gamma model to predict daily rainfall across Australia. By analyzing over 140,000 observations, we demonstrated that rainfall is driven by a complex interplay of **thermodynamic instability**, **wind vector dynamics**, and **spatial heterogeneity**.

The hurdle specification explicitly separates the rainfall process into two components: a logistic model for occurrence (will it rain?) and a truncated Gamma model for intensity conditional on occurrence (how much?). This approach aligns with the physical data-generating process and avoids the conceptual issues of zero-inflated models where the continuous component can also produce zeros.

Our progressive modeling strategy validated four critical physical hypotheses:

1\. **The "Rain Corner":** We mathematically defined the interaction between High Humidity and Low Sunshine, identifying it as the primary thermodynamic trigger for precipitation.

2. **Persistence:** Rainfall is highly state-dependent. A wet yesterday increases the probability of rain today by approximately **76%**, a finding robustly captured by our Markov chain features.

3\. **Wind Vectors:** Decomposing wind into $U$ (East-West) and $V$ (North-South) components revealed that Southerly and Westerly flows are the strongest drivers of rainfall intensity.

4\. **Spatial Variance:** Our Mixed Model (M6) revealed distinct geographic baselines, separating "wet" tropical zones from "dry" interior zones with high statistical confidence.

## Model Performance and Limitations

The final model (M6) offers a significant improvement over standard linear approaches:

-   **Classification:** It achieves an **AUC of 0.83**, indicating strong discriminative power in distinguishing wet days from dry days.

-   **General Intensity:** It achieves a **Mean Absolute Error (MAE) of 2.71 mm**, providing precise estimates for typical rainfall events.

-   **Limitation on Extremes:** The Global RMSE of **7.48 mm** indicates that the model under-predicts the magnitude of extreme outlier events (e.g., \>50mm). While the Gamma distribution handles skewness better than a Gaussian, it lacks the "heavy tail" required to fully capture rare, catastrophic storm events.

## Operational Suitability

Based on these metrics, we define the following scope for deployment:

-   **Suitable For:**
    -   **Short-term Forecasting:** Ideal for 1-7 day probabilistic forecasts of standard weather patterns.
    -   **Agricultural Planning:** Reliable for estimating soil moisture recharge and typical seasonal accumulation.
    -   **Data Imputation:** Excellent for reconstructing missing historical data for non-extreme days, as it respects the zero-bound constraint.
-   **Not Suitable For:**
    -   **Extreme Value Analysis (EVA):** The model should **not** be used to calculate 1-in-100-year flood risks or engineering design loads (e.g., dam capacities). These rare events require specialized Extreme Value Theory (EVT) distributions (e.g., Generalized Pareto).

## Final Recommendation

We recommend the **Mixed Effects Hurdle Gamma Model** as the standard for general meteorological inference. It successfully balances complexity and accuracy, solving the "negative rain" problem inherent in linear models while maintaining strict separation between occurrence and intensity processes. The hurdle specification ensures that the Gamma component is truncated at zero, preventing it from generating zeros and improving model interpretability. Future work should focus on integrating **Extreme Value Theory (EVT)** tails to better model the catastrophic outlier events that the current Gamma framework underestimates.